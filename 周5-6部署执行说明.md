周5-6 无人机视觉实训部署执行说明
================================

目标概述
--------
- 在 Windows (PowerShell) 环境下，从零搭建稳定可复现的检测算法训练流水线。
- 数据集：VisDrone-DET train/val。
- 模型：YOLOv8n（Ultralytics），确保可视化预测结果产出。
- 时间范围对应原计划第 5-6 周：完成环境搭建、数据准备、基线模型训练与评估。

目录结构约定
------------
```
D:\
 └─AIProjects\
     └─VisDrone_YOLOv8\
         ├─data\               # 原始数据与转换结果
         │   ├─VisDrone-DET\   # 官方压缩包解压
         │   └─yolo\           # 转换后 YOLO 格式
         ├─runs\               # 训练/验证/预测产物
         ├─scripts\            # 辅助脚本
         └─docs\               # 过程记录与报告
```

步骤 1：创建工程目录
--------------------
```powershell
New-Item -Path "D:\AIProjects\VisDrone_YOLOv8" -ItemType Directory -Force
Set-Location   "D:\AIProjects\VisDrone_YOLOv8"
New-Item -ItemType Directory -Path ".\data", ".\scripts", ".\docs" -Force | Out-Null
```

步骤 2：准备 Conda 环境
-----------------------
```powershell
# 创建并激活 Python 3.10 环境
conda create -n visdrone_yolov8 python=3.10 -y
conda activate visdrone_yolov8

# 固定版本安装，确保兼容性
pip install --upgrade pip setuptools wheel
pip install ultralytics==8.2.10 opencv-python-headless==4.9.0.80 pandas==2.1.4 tqdm==4.66.1

# 可选：开启 GPU (若已有 CUDA 11.8 + 对应驱动)
pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118
```

环境验证：
```powershell
python -c "import torch, ultralytics; print('torch', torch.__version__, 'cuda', torch.cuda.is_available()); print('ultralytics', ultralytics.__version__)"
```

步骤 3：数据集下载与解压
------------------------
> 若已手动下载，可将压缩包放入 `data\` 目录后直接执行解压步骤。

```powershell
$base = "D:\AIProjects\VisDrone_YOLOv8\data"
Set-Location $base

# 仅提供示例 URL，建议提前登录官网下载以保证速度
Invoke-WebRequest -Uri "https://github.com/VisDrone/VisDrone-Dataset/releases/download/VisDrone2019/VisDrone2019-DET-train.zip" -OutFile "VisDrone2019-DET-train.zip"
Invoke-WebRequest -Uri "https://github.com/VisDrone/VisDrone-Dataset/releases/download/VisDrone2019/VisDrone2019-DET-val.zip"   -OutFile "VisDrone2019-DET-val.zip"
Invoke-WebRequest -Uri "https://github.com/VisDrone/VisDrone-Dataset/releases/download/VisDrone2019/VisDrone2019-DET-test-dev.zip" -OutFile "VisDrone2019-DET-test-dev.zip"

# 解压
Expand-Archive .\VisDrone2019-DET-train.zip -DestinationPath . -Force
Expand-Archive .\VisDrone2019-DET-val.zip   -DestinationPath . -Force
Expand-Archive .\VisDrone2019-DET-test-dev.zip -DestinationPath . -Force

Rename-Item -Path ".\VisDrone2019-DET-train" -NewName "VisDrone-DET-train" -Force
Rename-Item -Path ".\VisDrone2019-DET-val"   -NewName "VisDrone-DET-val"   -Force
Rename-Item -Path ".\VisDrone2019-DET-test-dev" -NewName "VisDrone-DET-test" -Force
```

步骤 4：VisDrone → YOLO 格式转换
-------------------------------
1. 将以下脚本保存为 `scripts\visdrone_to_yolo.py`：

```python
from pathlib import Path
import argparse
import shutil
import json

CATEGORIES = [
    (1, "pedestrian"), (2, "people"), (3, "bicycle"), (4, "car"),
    (5, "van"), (6, "truck"), (7, "tricycle"), (8, "awning-tricycle"),
    (9, "bus"), (10, "motor"), (11, "others")
]

def convert_split(split: str, src_dir: Path, dst_dir: Path):
    img_dir = src_dir / split / "images"
    ann_dir = src_dir / split / "annotations"
    out_img = dst_dir / split / "images"
    out_lab = dst_dir / split / "labels"
    out_img.mkdir(parents=True, exist_ok=True)
    out_lab.mkdir(parents=True, exist_ok=True)

    for img_path in sorted(img_dir.glob("*.jpg")):
        shutil.copy(img_path, out_img / img_path.name)
        ann_txt = ann_dir / f"{img_path.stem}.txt"
        labels = []
        if ann_txt.exists():
            with ann_txt.open("r") as f:
                for line in f:
                    x, y, w, h, score, cid, trunc, occ = map(float, line.strip().split(",")[:8])
                    if cid < 1 or cid > len(CATEGORIES):
                        continue
                    # 转为 YOLO: class x_center y_center width height (相对坐标)
                    xc = (x + w / 2) / 960
                    yc = (y + h / 2) / 540
                    labels.append(f"{int(cid)-1} {xc:.6f} {yc:.6f} {(w/960):.6f} {(h/540):.6f}")
        (out_lab / f"{img_path.stem}.txt").write_text("\n".join(labels), encoding="utf-8")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--src", type=str, required=True, help="VisDrone-DET 根目录 (包含 train/val/test)")
    parser.add_argument("--dst", type=str, required=True, help="YOLO 输出目录")
    args = parser.parse_args()

    src_root = Path(args.src)
    dst_root = Path(args.dst)
    for split in ("train", "val", "test"):
        convert_split(split, src_root, dst_root)

    names = {i-1: name for i, name in CATEGORIES}
    (dst_root / "visdrone.yaml").write_text(
        "path: ../data/yolo\n"
        "train: train/images\n"
        "val: val/images\n"
        "test: test/images\n"
        "names:\n" + "\n".join([f"  {i}: {names[i]}" for i in range(len(names))]),
        encoding="utf-8"
    )
    print("✅ Conversion completed.")

if __name__ == "__main__":
    main()
```

2. 执行转换：
```powershell
Set-Location D:\AIProjects\VisDrone_YOLOv8
python .\scripts\visdrone_to_yolo.py --src ".\data\VisDrone-DET" --dst ".\data\yolo"
```

完成后检查 `data\yolo\visdrone.yaml` 与 `train/images` / `train/labels`。

步骤 5：训练基线模型
--------------------
```powershell
Set-Location D:\AIProjects\VisDrone_YOLOv8

yolo detect train `
    model=yolov8n.pt `
    data=data/yolo/visdrone.yaml `
    epochs=50 `
    imgsz=960 `
    batch=8 `
    project=runs/train `
    name=yolov8n_visdrone `
    pretrained=True
```
- 若显存不足，调小 `batch` 或 `imgsz`。
- 训练日志、权重与可视化曲线输出至 `runs/train/yolov8n_visdrone/`。

步骤 6：验证与预测可视化
------------------------
```powershell
# 验证 mAP、precision、recall
yolo detect val `
    model=runs/train/yolov8n_visdrone/weights/best.pt `
    data=data/yolo/visdrone.yaml `
    imgsz=960 `
    project=runs/val `
    name=yolov8n_visdrone

# 生成可视化预测图
yolo detect predict `
    model=runs/train/yolov8n_visdrone/weights/best.pt `
    source=data/yolo/val/images `
    imgsz=960 `
    save=True `
    save_txt=True `
    conf=0.25 `
    project=runs/predict `
    name=visdrone_val_samples
```
可视化结果保存在 `runs/predict/visdrone_val_samples/`，供系统展示或汇报使用。

步骤 7：记录与汇报
------------------
1. 将关键命令、损失曲线、预测样例截图整理到 `docs\week5-6_report.md`。
2. 必要时使用 `tensorboard --logdir runs` 打开可视化(ultralytics 自动写出 TB 日志)。
3. 若需集成现有 Streamlit Agent：可读取 `runs/predict/...` 中的图片并在 UI 展示。

常见问题排查
------------
- **CUDA 不可用**：执行 `python -c "import torch; print(torch.cuda.is_available())"`，返回 False 时默认走 CPU；可照旧训练但需适当降低 batch。
- **下载缓慢**：建议提前通过浏览器下载 VisDrone 压缩包，再移动至目标目录。
- **内存不足或训练慢**：调小 `epochs`（例如 30）、`batch`（4）、或 `imgsz`（640）。

交付检查列表
------------
- [ ] Conda 环境 `visdrone_yolov8` 可激活，`torch` 与 `ultralytics` 版本正确。
- [ ] `data/yolo/visdrone.yaml` 存在，且 `train/val` 目录均含 `images/labels`。
- [ ] 完成至少一次训练，`runs/train/yolov8n_visdrone/weights/best.pt` 生成。
- [ ] 生成预测图片，确认可用于 Streamlit/报告展示。
- [ ] `docs/week5-6_report.md` 记录训练指标与截图。

到此，第 5-6 周目标（环境、训练、可视化）即可落地执行。

