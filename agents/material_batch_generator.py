"""
æ— äººæœºç´ ææ‰¹é‡ç”Ÿæˆå™¨
Drone Material Batch Generator
åŸºäº8ç»´åº¦åˆ†æç»“æœï¼Œè‡ªåŠ¨æ‰¹é‡ç”Ÿæˆå’Œç­›é€‰é«˜è´¨é‡æ— äººæœºè§†è§‰ç´ æ
"""

import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import json
import shutil
from agents.image_quality_analyzer import ImageQualityAnalyzer
from agents.material_generator_agent import MaterialGeneratorAgent


class MaterialBatchGenerator:
    """æ— äººæœºç´ ææ‰¹é‡ç”Ÿæˆå™¨"""
    
    def __init__(self, yolo_model_path: Optional[str] = None):
        """
        åˆå§‹åŒ–æ‰¹é‡ç”Ÿæˆå™¨
        
        å‚æ•°:
            yolo_model_path: YOLOæ¨¡å‹è·¯å¾„
        """
        self.analyzer = ImageQualityAnalyzer(yolo_model_path)
        self.agent = MaterialGeneratorAgent(yolo_model_path)
        self.quality_threshold = 75.0  # é»˜è®¤è´¨é‡é˜ˆå€¼
        
    def generate_high_quality_materials(
        self,
        source_dir: str,
        output_dir: str,
        min_quality: float = 75.0,
        max_count: Optional[int] = None,
        dimension_weights: Optional[Dict[str, float]] = None
    ) -> Dict:
        """
        ä»æºç›®å½•æ‰¹é‡ç”Ÿæˆé«˜è´¨é‡ç´ æ
        
        å‚æ•°:
            source_dir: æºå›¾ç‰‡ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            min_quality: æœ€ä½è´¨é‡åˆ†æ•°
            max_count: æœ€å¤§ç”Ÿæˆæ•°é‡ï¼ˆNoneè¡¨ç¤ºä¸é™åˆ¶ï¼‰
            dimension_weights: ç»´åº¦æƒé‡ï¼ˆç”¨äºè‡ªå®šä¹‰è¯„åˆ†ï¼‰
            
        è¿”å›:
            ç”Ÿæˆç»“æœå­—å…¸
        """
        source_path = Path(source_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # è·å–æ‰€æœ‰å›¾ç‰‡
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
        image_paths = [
            str(p) for p in source_path.rglob('*')
            if p.suffix.lower() in image_extensions
        ]
        
        if not image_paths:
            return {
                'success': False,
                'message': f'åœ¨ {source_dir} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶',
                'total_images': 0,
                'generated_count': 0
            }
        
        print(f"ğŸ“¸ æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹åˆ†æ...")
        
        # æ‰¹é‡åˆ†æ
        analysis_result = self.agent.analyze_and_evaluate(image_paths)
        
        # ç­›é€‰é«˜è´¨é‡ç´ æ
        quality_scores = analysis_result['quality_evaluation']
        
        # åº”ç”¨è‡ªå®šä¹‰æƒé‡ï¼ˆå¦‚æœæœ‰ï¼‰
        if dimension_weights:
            for item in quality_scores:
                weighted_score = sum(
                    item['dimension_scores'].get(dim, 0) * weight
                    for dim, weight in dimension_weights.items()
                ) / sum(dimension_weights.values())
                item['weighted_score'] = weighted_score
                item['average_score'] = weighted_score
        
        # æŒ‰è´¨é‡æ’åº
        quality_scores.sort(key=lambda x: x['average_score'], reverse=True)
        
        # ç­›é€‰å¹¶å¤åˆ¶é«˜è´¨é‡ç´ æ
        high_quality = [
            q for q in quality_scores
            if q['average_score'] >= min_quality
        ]
        
        if max_count:
            high_quality = high_quality[:max_count]
        
        # å¤åˆ¶æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
        generated_files = []
        metadata = []
        
        for idx, item in enumerate(high_quality, 1):
            src_path = Path(item['image_path'])
            dst_path = output_path / f"high_quality_{idx:04d}_{src_path.name}"
            
            try:
                shutil.copy2(src_path, dst_path)
                generated_files.append(str(dst_path))
                
                metadata.append({
                    'index': idx,
                    'original_path': str(src_path),
                    'generated_path': str(dst_path),
                    'quality_score': item['average_score'],
                    'quality_level': item['quality_level'],
                    'dimension_scores': item['dimension_scores']
                })
                
                print(f"âœ… [{idx}/{len(high_quality)}] {src_path.name} (è´¨é‡: {item['average_score']:.2f}%)")
            except Exception as e:
                print(f"âŒ å¤åˆ¶å¤±è´¥ {src_path.name}: {e}")
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata_file = output_path / f"material_metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump({
                'generation_time': datetime.now().isoformat(),
                'source_dir': str(source_path),
                'output_dir': str(output_path),
                'min_quality': min_quality,
                'total_analyzed': len(image_paths),
                'generated_count': len(generated_files),
                'materials': metadata
            }, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        stats = self._generate_statistics(metadata, analysis_result)
        stats_file = output_path / f"generation_statistics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        return {
            'success': True,
            'total_images': len(image_paths),
            'generated_count': len(generated_files),
            'output_dir': str(output_path),
            'metadata_file': str(metadata_file),
            'statistics_file': str(stats_file),
            'generated_files': generated_files
        }
    
    def _generate_statistics(self, metadata: List[Dict], analysis_result: Dict) -> Dict:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        if not metadata:
            return {}
        
        scores = [m['quality_score'] for m in metadata]
        dimension_scores = {}
        
        for dim in self.analyzer.dimensions:
            dim_scores = [m['dimension_scores'].get(dim, 0) for m in metadata]
            dimension_scores[dim] = {
                'mean': float(np.mean(dim_scores)),
                'std': float(np.std(dim_scores)),
                'min': float(np.min(dim_scores)),
                'max': float(np.max(dim_scores))
            }
        
        return {
            'total_materials': len(metadata),
            'quality_statistics': {
                'mean': float(np.mean(scores)),
                'std': float(np.std(scores)),
                'min': float(np.min(scores)),
                'max': float(np.max(scores)),
                'median': float(np.median(scores))
            },
            'dimension_statistics': dimension_scores,
            'quality_distribution': {
                'excellent (>=90)': sum(1 for s in scores if s >= 90),
                'good (80-89)': sum(1 for s in scores if 80 <= s < 90),
                'medium (70-79)': sum(1 for s in scores if 70 <= s < 80),
                'fair (60-69)': sum(1 for s in scores if 60 <= s < 70)
            }
        }
    
    def generate_material_report(self, output_dir: str) -> str:
        """
        ç”Ÿæˆç´ ææŠ¥å‘Š
        
        å‚æ•°:
            output_dir: è¾“å‡ºç›®å½•
            
        è¿”å›:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        output_path = Path(output_dir)
        metadata_files = list(output_path.glob("material_metadata_*.json"))
        
        if not metadata_files:
            raise ValueError(f"åœ¨ {output_dir} ä¸­æœªæ‰¾åˆ°ç´ æå…ƒæ•°æ®æ–‡ä»¶")
        
        # è¯»å–æœ€æ–°çš„å…ƒæ•°æ®
        latest_metadata = max(metadata_files, key=lambda p: p.stat().st_mtime)
        with open(latest_metadata, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report_content = f"""# æ— äººæœºç´ ææ‰¹é‡ç”ŸæˆæŠ¥å‘Š

## ç”Ÿæˆä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {data['generation_time']}
- **æºç›®å½•**: {data['source_dir']}
- **è¾“å‡ºç›®å½•**: {data['output_dir']}
- **æœ€ä½è´¨é‡è¦æ±‚**: {data['min_quality']}%

## ç»Ÿè®¡ä¿¡æ¯
- **åˆ†æå›¾ç‰‡æ€»æ•°**: {data['total_analyzed']}
- **ç”Ÿæˆé«˜è´¨é‡ç´ ææ•°**: {data['generated_count']}
- **ç”Ÿæˆç‡**: {data['generated_count'] / data['total_analyzed'] * 100:.2f}%

## ç´ æåˆ—è¡¨

| åºå· | æ–‡ä»¶å | è´¨é‡åˆ†æ•° | è´¨é‡ç­‰çº§ | ä¸»è¦ä¼˜åŠ¿ç»´åº¦ |
|------|--------|----------|----------|--------------|
"""
        
        for material in data['materials']:
            # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„3ä¸ªç»´åº¦
            dim_scores = material['dimension_scores']
            top_dims = sorted(dim_scores.items(), key=lambda x: x[1], reverse=True)[:3]
            top_dims_str = ', '.join([f"{dim}({score:.1f}%)" for dim, score in top_dims])
            
            filename = Path(material['generated_path']).name
            report_content += f"| {material['index']} | {filename} | {material['quality_score']:.2f}% | {material['quality_level']} | {top_dims_str} |\n"
        
        report_content += f"""
## è¯¦ç»†ç»´åº¦åˆ†æ

"""
        
        # è¯»å–ç»Ÿè®¡æ–‡ä»¶
        stats_files = list(output_path.glob("generation_statistics_*.json"))
        if stats_files:
            latest_stats = max(stats_files, key=lambda p: p.stat().st_mtime)
            with open(latest_stats, 'r', encoding='utf-8') as f:
                stats = json.load(f)
            
            report_content += f"""
### è´¨é‡åˆ†å¸ƒ
- ä¼˜ç§€ (>=90%): {stats['quality_distribution']['excellent (>=90)']} å¼ 
- è‰¯å¥½ (80-89%): {stats['quality_distribution']['good (80-89)']} å¼ 
- ä¸­ç­‰ (70-79%): {stats['quality_distribution']['medium (70-79)']} å¼ 
- ä¸€èˆ¬ (60-69%): {stats['quality_distribution']['fair (60-69)']} å¼ 

### å¹³å‡ç»´åº¦å¾—åˆ†
"""
            for dim, stat in stats['dimension_statistics'].items():
                report_content += f"- **{dim}**: {stat['mean']:.2f}% (èŒƒå›´: {stat['min']:.1f}% - {stat['max']:.1f}%)\n"
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = output_path / f"material_generation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return str(report_file)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    generator = MaterialBatchGenerator()
    
    result = generator.generate_high_quality_materials(
        source_dir="test_images",
        output_dir="generated_materials",
        min_quality=75.0,
        max_count=10
    )
    
    print("\nç”Ÿæˆç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))




