# ç¬¬4å‘¨ï¼šå®Œæ•´è®­ç»ƒæµç¨‹æµ‹è¯• - Windows PowerShellæ‰§è¡Œè®¡åˆ’

## ğŸ“‹ æ‰§è¡Œç¯å¢ƒå‡†å¤‡

**å‰ææ¡ä»¶ï¼š**
- âœ… å·²æ¿€æ´» `drone_vision_clean` ç¯å¢ƒï¼ˆæˆ– `drone_vision` ç¯å¢ƒï¼‰
- âœ… å·¥ä½œç›®å½•ï¼š`D:\mlflow_learning_project` æˆ– `C:\Windows\system32\drone_vision_project`
- âœ… Pythonç‰ˆæœ¬ï¼š3.7+
- âœ… å·²å®‰è£…åŸºç¡€ä¾èµ–ï¼šmlflow, matplotlib, opencv-python, pillow

---

## ğŸ—“ï¸ ç¬¬4å‘¨æ¯æ—¥ä»»åŠ¡æ¸…å•

### ğŸ“… å‘¨ä¸€ï¼šå°è§„æ¨¡æ•°æ®é›†å‡†å¤‡

#### ğŸŒ… ä¸Šåˆ (9:00-12:00) - æ•°æ®é›†ä¸‹è½½ä¸é¢„å¤„ç†

**æ­¥éª¤1ï¼šå‡†å¤‡å·¥ä½œç¯å¢ƒï¼ˆ5åˆ†é’Ÿï¼‰**
```powershell
# 1. æ‰“å¼€PowerShellï¼ˆç®¡ç†å‘˜æƒé™ï¼‰
# 2. æ¿€æ´»condaç¯å¢ƒ
conda activate drone_vision_clean

# 3. åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•ï¼ˆæ ¹æ®ä½ çš„å®é™…è·¯å¾„é€‰æ‹©ï¼‰
cd D:\mlflow_learning_project
# æˆ–è€…
cd C:\Windows\system32\drone_vision_project

# 4. åˆ›å»ºæ•°æ®é›†ç›®å½•ç»“æ„
New-Item -ItemType Directory -Force -Path data\external\visdrone
New-Item -ItemType Directory -Force -Path data\processed\visdrone
New-Item -ItemType Directory -Force -Path data\raw\images
New-Item -ItemType Directory -Force -Path data\raw\annotations

# 5. éªŒè¯ç›®å½•åˆ›å»ºæˆåŠŸ
tree /F data
```

**æ­¥éª¤2ï¼šå®‰è£…å¿…è¦çš„PythonåŒ…ï¼ˆ10åˆ†é’Ÿï¼‰**
```powershell
# å®‰è£…æ•°æ®å¤„ç†ç›¸å…³åŒ…
pip install opencv-python pillow pyyaml numpy pandas

# éªŒè¯å®‰è£…

```

**æ­¥éª¤3ï¼šä¸‹è½½VisDroneæ•°æ®é›†ï¼ˆå¯é€‰ï¼Œå¦‚æœç½‘ç»œå…è®¸ï¼‰ï¼ˆ30-60åˆ†é’Ÿï¼‰**

**é€‰é¡¹Aï¼šä»GitHubå…‹éš†ï¼ˆæ¨èç”¨äºå­¦ä¹ ï¼‰**
```powershell
cd data\external\visdrone
git clone https://github.com/VisDrone/VisDrone-Dataset.git

# å¦‚æœæ²¡æœ‰gitï¼Œå¯ä»¥ç”¨æµè§ˆå™¨ä¸‹è½½zipåŒ…
# è®¿é—®ï¼šhttps://github.com/VisDrone/VisDrone-Dataset
# ä¸‹è½½åè§£å‹åˆ° data\external\visdrone ç›®å½•
```

**é€‰é¡¹Bï¼šåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†ï¼ˆå¦‚æœæ— æ³•ä¸‹è½½çœŸå®æ•°æ®ï¼‰**
```powershell
# å›åˆ°é¡¹ç›®æ ¹ç›®å½•
cd D:\mlflow_learning_project
# æˆ– cd C:\Windows\system32\drone_vision_project

# è¿è¡Œä¹‹å‰åˆ›å»ºçš„prepare_test_images.pyç”Ÿæˆæµ‹è¯•æ•°æ®
python scripts\prepare_test_images.py
```

**æ­¥éª¤4ï¼šåˆ›å»ºVisDroneæ•°æ®é¢„å¤„ç†è„šæœ¬ï¼ˆ30åˆ†é’Ÿï¼‰**

åœ¨PowerShellä¸­æ‰§è¡Œï¼š
```powershell
# åœ¨scriptsç›®å½•åˆ›å»ºvisdrone_processor.py
New-Item -ItemType File -Path scripts\visdrone_processor.py -Force
```

ç„¶åæˆ‘ä¼šæä¾›å®Œæ•´çš„è„šæœ¬å†…å®¹ï¼ˆè§ä¸‹æ–¹ï¼‰ã€‚

---

#### ğŸ“ è„šæœ¬1ï¼švisdrone_processor.py

åœ¨PyCharmæˆ–æ–‡æœ¬ç¼–è¾‘å™¨ä¸­æ‰“å¼€ `scripts/visdrone_processor.py`ï¼Œè¾“å…¥ä»¥ä¸‹ä»£ç ï¼š

```python
"""
VisDroneæ•°æ®é›†é¢„å¤„ç†è„šæœ¬
ç”¨äºå°†VisDroneæ ¼å¼è½¬æ¢ä¸ºCOCOæ ¼å¼å¹¶è°ƒæ•´å›¾åƒå°ºå¯¸
"""
import os
import json
from pathlib import Path
from PIL import Image


class VisDroneProcessor:
    def __init__(self, data_path="data/external/visdrone"):
        self.data_path = Path(data_path)
        self.output_path = Path("data/processed/visdrone")
        self.class_names = [
            'ignored regions', 'pedestrian', 'people', 'bicycle', 'car', 
            'van', 'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor'
        ]
    
    def process_dataset(self):
        """å¤„ç†æ•´ä¸ªæ•°æ®é›†"""
        print("å¼€å§‹å¤„ç†VisDroneæ•°æ®é›†...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        # å¤„ç†è®­ç»ƒé›†
        self.process_split("train")
        
        # å¤„ç†éªŒè¯é›†
        self.process_split("val")
        
        print("æ•°æ®é›†å¤„ç†å®Œæˆï¼")
    
    def process_split(self, split_name):
        """å¤„ç†ç‰¹å®šåˆ†å‰²çš„æ•°æ®"""
        print(f"\nå¤„ç†{split_name}é›†...")
        
        # åˆ›å»ºåˆ†å‰²ç›®å½•
        split_dir = self.output_path / split_name
        split_dir.mkdir(exist_ok=True)
        
        # å¤„ç†å›¾åƒ
        images_dir = split_dir / "images"
        images_dir.mkdir(exist_ok=True)
        
        # å¤„ç†æ ‡æ³¨
        annotations_dir = split_dir / "annotations"
        annotations_dir.mkdir(exist_ok=True)
        
        # æŸ¥æ‰¾æºæ•°æ®ç›®å½•ï¼ˆé€‚é…å¤šç§å¯èƒ½çš„è·¯å¾„ï¼‰
        possible_paths = [
            self.data_path / f"VisDrone2019-DET-{split_name}",
            self.data_path / f"VisDrone-Dataset" / f"VisDrone2019-DET-{split_name}",
            Path("data/raw/images")  # å¦‚æœä½¿ç”¨æµ‹è¯•æ•°æ®
        ]
        
        source_images_dir = None
        for path in possible_paths:
            if path.exists():
                source_images_dir = path / "images"
                source_annotations_dir = path / "annotations"
                break
        
        if source_images_dir and source_images_dir.exists():
            print(f"  æ‰¾åˆ°æºå›¾åƒç›®å½•: {source_images_dir}")
            # å¤„ç†å›¾åƒ
            image_count = 0
            for img_file in source_images_dir.glob("*.jpg"):
                try:
                    # è°ƒæ•´å›¾åƒå¤§å°
                    processed_img = self.resize_image(img_file, max_size=(640, 640))
                    processed_img.save(images_dir / img_file.name)
                    image_count += 1
                except Exception as e:
                    print(f"  å¤„ç†å›¾åƒå¤±è´¥ {img_file.name}: {e}")
            print(f"  å·²å¤„ç† {image_count} å¼ å›¾åƒ")
        else:
            print(f"  è­¦å‘Š: æœªæ‰¾åˆ°{split_name}é›†çš„æºå›¾åƒç›®å½•")
            print(f"  å°è¯•çš„è·¯å¾„: {[str(p) for p in possible_paths]}")
        
        # è½¬æ¢æ ‡æ³¨æ ¼å¼
        source_annotations_dir = self.data_path / f"VisDrone2019-DET-{split_name}" / "annotations"
        if not source_annotations_dir.exists():
            source_annotations_dir = Path("data/raw/annotations")
        
        if source_annotations_dir.exists():
            coco_annotations = self.convert_to_coco_format(
                source_annotations_dir, images_dir, split_name
            )
            
            # ä¿å­˜COCOæ ¼å¼æ ‡æ³¨
            output_file = annotations_dir / "annotations.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(coco_annotations, f, indent=2, ensure_ascii=False)
            print(f"  å·²ä¿å­˜COCOæ ¼å¼æ ‡æ³¨: {output_file}")
        else:
            print(f"  è­¦å‘Š: æœªæ‰¾åˆ°æ ‡æ³¨ç›®å½•ï¼Œåˆ›å»ºç©ºæ ‡æ³¨æ–‡ä»¶")
            # åˆ›å»ºç©ºçš„COCOæ ¼å¼æ–‡ä»¶
            empty_coco = {
                "images": [],
                "annotations": [],
                "categories": []
            }
            for i, class_name in enumerate(self.class_names):
                empty_coco["categories"].append({
                    "id": i,
                    "name": class_name,
                    "supercategory": "object"
                })
            with open(annotations_dir / "annotations.json", 'w', encoding='utf-8') as f:
                json.dump(empty_coco, f, indent=2, ensure_ascii=False)
    
    def resize_image(self, image_path, max_size=(640, 640)):
        """è°ƒæ•´å›¾åƒå¤§å°"""
        img = Image.open(image_path)
        img.thumbnail(max_size, Image.Resampling.LANCZOS)
        return img
    
    def convert_to_coco_format(self, annotations_dir, images_dir, split_name):
        """è½¬æ¢ä¸ºCOCOæ ¼å¼"""
        coco_data = {
            "images": [],
            "annotations": [],
            "categories": []
        }
        
        # æ·»åŠ ç±»åˆ«ä¿¡æ¯
        for i, class_name in enumerate(self.class_names):
            coco_data["categories"].append({
                "id": i,
                "name": class_name,
                "supercategory": "object"
            })
        
        image_id = 0
        annotation_id = 0
        
        # å¤„ç†æ¯ä¸ªå›¾åƒ
        for img_file in images_dir.glob("*.jpg"):
            try:
                # æ·»åŠ å›¾åƒä¿¡æ¯
                img = Image.open(img_file)
                coco_data["images"].append({
                    "id": image_id,
                    "file_name": img_file.name,
                    "width": img.size[0],
                    "height": img.size[1]
                })
                
                # å¤„ç†å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶ï¼ˆVisDroneæ ¼å¼ï¼šæ¯å¼ å›¾å¯¹åº”ä¸€ä¸ª.txtæ–‡ä»¶ï¼‰
                annotation_file = annotations_dir / (img_file.stem + ".txt")
                if annotation_file.exists():
                    with open(annotation_file, 'r', encoding='utf-8') as f:
                        for line in f:
                            line = line.strip()
                            if not line:
                                continue
                            parts = line.split(',')
                            if len(parts) >= 8:
                                try:
                                    # VisDroneæ ¼å¼: <bbox_left>,<bbox_top>,<bbox_width>,<bbox_height>,<score>,<object_category>,<truncation>,<occlusion>
                                    bbox_left = int(parts[0])
                                    bbox_top = int(parts[1])
                                    bbox_width = int(parts[2])
                                    bbox_height = int(parts[3])
                                    category_id = int(parts[5])  # VisDroneç±»åˆ«ID
                                    
                                    # è·³è¿‡å¿½ç•¥åŒºåŸŸ
                                    if category_id == 0:
                                        continue
                                    
                                    # è½¬æ¢ä¸ºCOCOæ ¼å¼ï¼ˆCOCOæ ¼å¼ï¼šbbox = [x, y, width, height]ï¼‰
                                    coco_data["annotations"].append({
                                        "id": annotation_id,
                                        "image_id": image_id,
                                        "category_id": category_id,
                                        "bbox": [bbox_left, bbox_top, bbox_width, bbox_height],
                                        "area": bbox_width * bbox_height,
                                        "iscrowd": 0
                                    })
                                    annotation_id += 1
                                except (ValueError, IndexError) as e:
                                    print(f"  è§£ææ ‡æ³¨è¡Œå¤±è´¥: {line[:50]}... - {e}")
                                    continue
                
                image_id += 1
            except Exception as e:
                print(f"  å¤„ç†å›¾åƒå¤±è´¥ {img_file.name}: {e}")
                continue
        
        print(f"  è½¬æ¢å®Œæˆ: {len(coco_data['images'])} å¼ å›¾åƒ, {len(coco_data['annotations'])} ä¸ªæ ‡æ³¨")
        return coco_data


if __name__ == "__main__":
    processor = VisDroneProcessor()
    processor.process_dataset()
    print("\nâœ… VisDroneæ•°æ®é¢„å¤„ç†å®Œæˆï¼")
```

**æ­¥éª¤5ï¼šè¿è¡Œé¢„å¤„ç†è„šæœ¬ï¼ˆ10åˆ†é’Ÿï¼‰**
```powershell
# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
python scripts\visdrone_processor.py

# æ£€æŸ¥è¾“å‡º
tree /F data\processed\visdrone
```

---

#### ğŸŒ† ä¸‹åˆ (14:00-18:00) - æ•°æ®éªŒè¯ä¸è´¨é‡æ£€æŸ¥

**æ­¥éª¤6ï¼šåˆ›å»ºæ•°æ®éªŒè¯è„šæœ¬ï¼ˆ60åˆ†é’Ÿï¼‰**

åœ¨PowerShellä¸­åˆ›å»ºæ–‡ä»¶ï¼š
```powershell
New-Item -ItemType File -Path scripts\data_validation.py -Force
```

---

#### ğŸ“ è„šæœ¬2ï¼šdata_validation.py

```python
"""
æ•°æ®éªŒè¯è„šæœ¬
ç”¨äºéªŒè¯å¤„ç†åçš„æ•°æ®é›†è´¨é‡å’Œå®Œæ•´æ€§
"""
import json
from pathlib import Path
import cv2
import numpy as np
from collections import Counter


class DataValidator:
    def __init__(self, data_path="data/processed/visdrone"):
        self.data_path = Path(data_path)
        self.validation_report = {}
    
    def validate_dataset(self):
        """éªŒè¯æ•´ä¸ªæ•°æ®é›†"""
        print("=" * 60)
        print("å¼€å§‹éªŒè¯æ•°æ®é›†...")
        print("=" * 60)
        
        for split in ["train", "val", "test"]:
            split_path = self.data_path / split
            if split_path.exists():
                print(f"\néªŒè¯ {split} é›†...")
                self.validation_report[split] = self.validate_split(split_path)
            else:
                print(f"\nè·³è¿‡ {split} é›†ï¼ˆç›®å½•ä¸å­˜åœ¨ï¼‰")
        
        # ç”ŸæˆéªŒè¯æŠ¥å‘Š
        self.generate_validation_report()
        
        return self.validation_report
    
    def validate_split(self, split_path):
        """éªŒè¯ç‰¹å®šåˆ†å‰²çš„æ•°æ®"""
        images_dir = split_path / "images"
        annotations_file = split_path / "annotations" / "annotations.json"
        
        validation_result = {
            "total_images": 0,
            "valid_images": 0,
            "total_annotations": 0,
            "image_issues": [],
            "annotation_issues": [],
            "class_distribution": {},
            "size_distribution": {}
        }
        
        # éªŒè¯å›¾åƒ
        if images_dir.exists():
            image_files = list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.png"))
            validation_result["total_images"] = len(image_files)
            
            for img_file in image_files:
                try:
                    img = cv2.imread(str(img_file))
                    if img is None:
                        validation_result["image_issues"].append(f"æ— æ³•è¯»å–å›¾åƒ: {img_file.name}")
                    else:
                        validation_result["valid_images"] += 1
                        # è®°å½•å›¾åƒå°ºå¯¸åˆ†å¸ƒ
                        h, w = img.shape[:2]
                        size_key = f"{w}x{h}"
                        validation_result["size_distribution"][size_key] = \
                            validation_result["size_distribution"].get(size_key, 0) + 1
                except Exception as e:
                    validation_result["image_issues"].append(f"å›¾åƒå¤„ç†é”™è¯¯: {img_file.name} - {e}")
        else:
            validation_result["image_issues"].append("å›¾åƒç›®å½•ä¸å­˜åœ¨")
        
        # éªŒè¯æ ‡æ³¨
        if annotations_file.exists():
            try:
                with open(annotations_file, 'r', encoding='utf-8') as f:
                    coco_data = json.load(f)
                
                validation_result["total_annotations"] = len(coco_data.get("annotations", []))
                
                # æ£€æŸ¥æ ‡æ³¨è´¨é‡
                for annotation in coco_data.get("annotations", []):
                    bbox = annotation.get("bbox", [])
                    if len(bbox) != 4:
                        validation_result["annotation_issues"].append(
                            f"æ ‡æ³¨æ ¼å¼é”™è¯¯ (ID: {annotation.get('id', 'unknown')})"
                        )
                    elif bbox[2] <= 0 or bbox[3] <= 0:
                        validation_result["annotation_issues"].append(
                            f"æ ‡æ³¨å°ºå¯¸é”™è¯¯ (ID: {annotation.get('id', 'unknown')})"
                        )
                    
                    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
                    category_id = annotation.get("category_id", 0)
                    cat_str = str(category_id)
                    validation_result["class_distribution"][cat_str] = \
                        validation_result["class_distribution"].get(cat_str, 0) + 1
                
                print(f"  âœ… å›¾åƒ: {validation_result['valid_images']}/{validation_result['total_images']} æœ‰æ•ˆ")
                print(f"  âœ… æ ‡æ³¨: {validation_result['total_annotations']} ä¸ª")
                if validation_result["image_issues"]:
                    print(f"  âš ï¸  å›¾åƒé—®é¢˜: {len(validation_result['image_issues'])} ä¸ª")
                if validation_result["annotation_issues"]:
                    print(f"  âš ï¸  æ ‡æ³¨é—®é¢˜: {len(validation_result['annotation_issues'])} ä¸ª")
                
            except Exception as e:
                validation_result["annotation_issues"].append(f"è¯»å–æ ‡æ³¨æ–‡ä»¶å¤±è´¥: {e}")
        else:
            validation_result["annotation_issues"].append("æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨")
        
        return validation_result
    
    def generate_validation_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report_file = self.data_path / "validation_report.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.validation_report, f, indent=2, ensure_ascii=False)
        
        print("\n" + "=" * 60)
        print("æ•°æ®é›†éªŒè¯æ‘˜è¦")
        print("=" * 60)
        
        for split, result in self.validation_report.items():
            print(f"\n{split.upper()} é›†:")
            print(f"  å›¾åƒæ•°é‡: {result['total_images']}")
            print(f"  æœ‰æ•ˆå›¾åƒ: {result['valid_images']}")
            print(f"  æ ‡æ³¨æ•°é‡: {result['total_annotations']}")
            print(f"  å›¾åƒé—®é¢˜: {len(result['image_issues'])}")
            print(f"  æ ‡æ³¨é—®é¢˜: {len(result['annotation_issues'])}")
            
            if result['class_distribution']:
                print(f"  ç±»åˆ«åˆ†å¸ƒ: {dict(list(result['class_distribution'].items())[:5])}...")
        
        print(f"\nâœ… éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_file}")


if __name__ == "__main__":
    validator = DataValidator()
    validator.validate_dataset()
    print("\nâœ… æ•°æ®éªŒè¯å®Œæˆï¼")
```

**æ­¥éª¤7ï¼šè¿è¡ŒéªŒè¯è„šæœ¬ï¼ˆ10åˆ†é’Ÿï¼‰**
```powershell
python scripts\data_validation.py

# æŸ¥çœ‹éªŒè¯æŠ¥å‘Š
type data\processed\visdrone\validation_report.json
```

---http://127.0.0.1:5000

**æ­¥éª¤8ï¼šåˆ›å»ºæ•°æ®ç»Ÿè®¡åˆ†æè„šæœ¬ï¼ˆå¯é€‰ï¼Œå¦‚æœæ—¶é—´å…è®¸ï¼‰**

```powershell
New-Item -ItemType File -Path scripts\dataset_stats.py -Force
```

---

### ğŸ“… å‘¨äºŒï¼šDVCæ•°æ®ç‰ˆæœ¬ç®¡ç†æµ‹è¯•

#### ğŸŒ… ä¸Šåˆ (9:00-12:00)

**æ­¥éª¤1ï¼šæ£€æŸ¥DVCç¯å¢ƒï¼ˆ5åˆ†é’Ÿï¼‰**
```powershell
# æ£€æŸ¥DVCæ˜¯å¦å®‰è£…
dvc --version

# å¦‚æœæœªå®‰è£…ï¼Œåˆ™å®‰è£…
pip install dvc

# æ£€æŸ¥DVCçŠ¶æ€
dvc status
```

**æ­¥éª¤2ï¼šæ·»åŠ æ•°æ®åˆ°DVCï¼ˆ30åˆ†é’Ÿï¼‰**
```powershell
# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
# å¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–DVC
dvc init

# æ·»åŠ å¤„ç†åæ•°æ®åˆ°DVC
dvc add data\processed\visdrone

# æŸ¥çœ‹DVCæ–‡ä»¶
git status
dir data*.dvc
```

**æ­¥éª¤3ï¼šæäº¤åˆ°Gitï¼ˆ10åˆ†é’Ÿï¼‰**
```powershell
# æ·»åŠ DVCæ–‡ä»¶åˆ°Git
git add data\processed\visdrone.dvc
git add .dvc\config

# æäº¤
git commit -m "Add processed VisDrone dataset v1.0"

# æŸ¥çœ‹DVCè·Ÿè¸ªçš„æ•°æ®
dvc list data\processed\visdrone
```

---

### ğŸ“… å‘¨ä¸‰ï¼šMLflowå®éªŒè·Ÿè¸ªé›†æˆ

#### ğŸŒ… ä¸Šåˆ (9:00-12:00)

**æ­¥éª¤1ï¼šåˆ›å»ºMLflowä¸DVCé›†æˆè„šæœ¬ï¼ˆ30åˆ†é’Ÿï¼‰**

```powershell
New-Item -ItemType File -Path scripts\train_with_mlflow.py -Force
```

---

#### ğŸ“ è„šæœ¬3ï¼štrain_with_mlflow.py

```python
"""
å¸¦MLflowè·Ÿè¸ªçš„è®­ç»ƒè„šæœ¬
é›†æˆDVCæ•°æ®ç‰ˆæœ¬å’ŒMLflowå®éªŒè·Ÿè¸ª
"""
import mlflow
import mlflow.pytorch
from pathlib import Path
import json
from datetime import datetime


def main():
    # è®¾ç½®MLflowå®éªŒ
    experiment_name = "drone_vision_week4"
    mlflow.set_experiment(experiment_name)
    
    # å¼€å§‹MLflowè¿è¡Œ
    with mlflow.start_run(run_name=f"week4_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
        
        # 1. è®°å½•æ•°æ®ä¿¡æ¯
        data_path = Path("data/processed/visdrone")
        mlflow.log_param("data_path", str(data_path))
        mlflow.log_param("data_version", "v1.0")
        
        # è®°å½•æ•°æ®é›†ç»Ÿè®¡
        validation_report_path = data_path / "validation_report.json"
        if validation_report_path.exists():
            with open(validation_report_path, 'r') as f:
                validation_report = json.load(f)
            
            for split, stats in validation_report.items():
                mlflow.log_metric(f"{split}_images", stats.get("total_images", 0))
                mlflow.log_metric(f"{split}_annotations", stats.get("total_annotations", 0))
        
        # 2. è®°å½•æ¨¡å‹å‚æ•°ï¼ˆç¤ºä¾‹ï¼‰
        params = {
            "model": "yolov5",
            "epochs": 10,
            "batch_size": 16,
            "learning_rate": 0.001,
            "image_size": 640
        }
        
        for key, value in params.items():
            mlflow.log_param(key, value)
        
        # 3. æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ï¼ˆè®°å½•æŒ‡æ ‡ï¼‰
        print("å¼€å§‹æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹...")
        import time
        import random
        
        for epoch in range(1, params["epochs"] + 1):
            # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
            train_loss = 1.0 / epoch + random.uniform(0, 0.1)
            val_loss = 1.0 / epoch + random.uniform(0.05, 0.15)
            
            mlflow.log_metric("train_loss", train_loss, step=epoch)
            mlflow.log_metric("val_loss", val_loss, step=epoch)
            
            print(f"Epoch {epoch}/{params['epochs']}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}")
            time.sleep(0.2)
        
        # 4. è®°å½•æœ€ç»ˆæŒ‡æ ‡
        final_accuracy = 0.85 + random.uniform(-0.05, 0.05)
        mlflow.log_metric("final_accuracy", final_accuracy)
        mlflow.log_metric("final_val_loss", val_loss)
        
        # 5. ä¿å­˜éªŒè¯æŠ¥å‘Šä½œä¸ºartifact
        if validation_report_path.exists():
            mlflow.log_artifact(str(validation_report_path), "reports")
        
        print(f"\nâœ… è®­ç»ƒå®Œæˆï¼æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.4f}")
        print(f"ğŸ“Š æŸ¥çœ‹MLflow UI: mlflow ui")


if __name__ == "__main__":
    main()
```

**æ­¥éª¤2ï¼šè¿è¡Œè®­ç»ƒè„šæœ¬ï¼ˆ20åˆ†é’Ÿï¼‰**
```powershell
python scripts\train_with_mlflow.py

# å¯åŠ¨MLflow UIæŸ¥çœ‹ç»“æœ
mlflow ui --port 5000

# åœ¨æµè§ˆå™¨æ‰“å¼€: http://127.0.0.1:5000
```

---

### ğŸ“… å‘¨å››ï¼šå®Œæ•´è®­ç»ƒæµç¨‹æµ‹è¯•

#### ğŸŒ… ä¸Šåˆ (9:00-12:00)

**æ­¥éª¤1ï¼šåˆ›å»ºå®Œæ•´è®­ç»ƒæµç¨‹è„šæœ¬**

æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªç«¯åˆ°ç«¯çš„è®­ç»ƒæµç¨‹ã€‚

**æ­¥éª¤2ï¼šæµ‹è¯•å®Œæ•´æµç¨‹ï¼ˆ60åˆ†é’Ÿï¼‰**
```powershell
# 1. æ•°æ®é¢„å¤„ç†
python scripts\visdrone_processor.py

# 2. æ•°æ®éªŒè¯
python scripts\data_validation.py

# 3. è¿è¡Œè®­ç»ƒï¼ˆå¸¦MLflowè·Ÿè¸ªï¼‰
python scripts\train_with_mlflow.py

# 4. æŸ¥çœ‹ç»“æœ
mlflow ui
```

---

### ğŸ“… å‘¨äº”ï¼šæ–‡æ¡£ç¼–å†™ä¸æ€»ç»“

#### ğŸŒ… ä¸Šåˆ (9:00-12:00)

**æ­¥éª¤1ï¼šåˆ›å»ºå·¥ä½œæ€»ç»“æ–‡æ¡£**
```powershell
New-Item -ItemType File -Path ç¬¬4å‘¨å·¥ä½œæ€»ç»“.md -Force
```

**æ­¥éª¤2ï¼šè¿è¡Œæœ€ç»ˆæµ‹è¯•**
```powershell
# å®Œæ•´æµç¨‹æµ‹è¯•
python scripts\visdrone_processor.py
python scripts\data_validation.py
python scripts\train_with_mlflow.py

# æ£€æŸ¥æ‰€æœ‰è¾“å‡º
tree /F data\processed
dir outputs
```

---

## âœ… æ¯æ—¥æ£€æŸ¥æ¸…å•

### å‘¨ä¸€æ£€æŸ¥
- [ ] æ•°æ®é›†ç›®å½•ç»“æ„å·²åˆ›å»º
- [ ] é¢„å¤„ç†è„šæœ¬è¿è¡ŒæˆåŠŸ
- [ ] éªŒè¯è„šæœ¬è¿è¡ŒæˆåŠŸ
- [ ] ç”Ÿæˆäº†éªŒè¯æŠ¥å‘Š

### å‘¨äºŒæ£€æŸ¥
- [ ] DVCå·²åˆå§‹åŒ–
- [ ] æ•°æ®å·²æ·»åŠ åˆ°DVC
- [ ] Gitæäº¤æˆåŠŸ

### å‘¨ä¸‰æ£€æŸ¥
- [ ] MLflowè„šæœ¬è¿è¡ŒæˆåŠŸ
- [ ] MLflow UIå¯ä»¥è®¿é—®
- [ ] å®éªŒè®°å½•å·²ä¿å­˜

### å‘¨å››æ£€æŸ¥
- [ ] å®Œæ•´æµç¨‹æµ‹è¯•é€šè¿‡
- [ ] æ‰€æœ‰ç»„ä»¶æ­£å¸¸å·¥ä½œ

### å‘¨äº”æ£€æŸ¥
- [ ] æ–‡æ¡£å·²ç¼–å†™
- [ ] æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ

---

## ğŸš¨ å¸¸è§é—®é¢˜è§£å†³

### é—®é¢˜1ï¼šPowerShellå‘½ä»¤æ‰§è¡Œç­–ç•¥é™åˆ¶
```powershell
# å¦‚æœé‡åˆ°"æ— æ³•åŠ è½½æ–‡ä»¶ï¼Œå› ä¸ºåœ¨æ­¤ç³»ç»Ÿä¸Šç¦æ­¢è¿è¡Œè„šæœ¬"
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### é—®é¢˜2ï¼šæ‰¾ä¸åˆ°condaç¯å¢ƒ
```powershell
# æŸ¥æ‰¾condaå®‰è£…è·¯å¾„
where.exe conda

# æ‰‹åŠ¨æ¿€æ´»ç¯å¢ƒ
C:\Users\ä½ çš„ç”¨æˆ·å\.conda\envs\drone_vision_clean\python.exe
```

### é—®é¢˜3ï¼šæ¨¡å—å¯¼å…¥é”™è¯¯
```powershell
# å®‰è£…ç¼ºå¤±çš„åŒ…
pip install åŒ…å

# æ£€æŸ¥å·²å®‰è£…çš„åŒ…
pip list
```

### é—®é¢˜4ï¼šè·¯å¾„é—®é¢˜
```powershell
# ä½¿ç”¨ç»å¯¹è·¯å¾„
cd D:\mlflow_learning_project

# æˆ–ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆç¡®ä¿åœ¨æ­£ç¡®ç›®å½•ï¼‰
pwd  # æŸ¥çœ‹å½“å‰ç›®å½•
```

---

## ğŸ“Š é¢„æœŸè¾“å‡º

å®Œæˆç¬¬4å‘¨ä»»åŠ¡åï¼Œä½ åº”è¯¥æœ‰ï¼š

1. **æ•°æ®ç»“æ„**ï¼š
   ```
   data/
   â”œâ”€â”€ processed/
   â”‚   â””â”€â”€ visdrone/
   â”‚       â”œâ”€â”€ train/
   â”‚       â”‚   â”œâ”€â”€ images/
   â”‚       â”‚   â””â”€â”€ annotations/
   â”‚       â””â”€â”€ validation_report.json
   ```

2. **è„šæœ¬æ–‡ä»¶**ï¼š
   - `scripts/visdrone_processor.py`
   - `scripts/data_validation.py`
   - `scripts/train_with_mlflow.py`

3. **MLflowå®éªŒç»“æœ**ï¼š
   - å®éªŒè®°å½•åœ¨ `mlruns/` ç›®å½•
   - å¯ä»¥é€šè¿‡ `mlflow ui` æŸ¥çœ‹

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

- âœ… æ•°æ®é›†é¢„å¤„ç†å®Œæˆï¼Œè¾“å‡ºåˆ° `data/processed/visdrone`
- âœ… æ•°æ®éªŒè¯é€šè¿‡ï¼Œç”Ÿæˆäº†éªŒè¯æŠ¥å‘Š
- âœ… MLflowå®éªŒæˆåŠŸè¿è¡Œï¼Œè®°å½•äº†è®­ç»ƒè¿‡ç¨‹
- âœ… æ‰€æœ‰è„šæœ¬å¯ä»¥ç‹¬ç«‹è¿è¡Œ
- âœ… æ–‡æ¡£å®Œæ•´ï¼Œå¯ä»¥å¤ç°æ•´ä¸ªæµç¨‹

---

**ç¥ä½ ç¬¬4å‘¨å·¥ä½œé¡ºåˆ©ï¼** ğŸš€

