# ç¬¬7-8å‘¨å®æ–½è¯¦ç»†æ­¥éª¤ - æ‰§è¡ŒæŒ‡å—

## ğŸ“… æ—¶é—´å®‰æ’

### ç¬¬7å‘¨ï¼ˆ5ä¸ªå·¥ä½œæ—¥ï¼‰

#### Day 1: ç¯å¢ƒæ­å»ºä¸æ•°æ®å‡†å¤‡
**ç›®æ ‡**ï¼šå®Œæˆå¼€å‘ç¯å¢ƒæ­å»ºå’Œæ•°æ®é›†å‡†å¤‡

**ä»»åŠ¡æ¸…å•**ï¼š
```powershell
# 1. åˆ›å»ºæ–°çš„Condaç¯å¢ƒ
conda create -n drone_vision_advanced python=3.10 -y
conda activate drone_vision_advanced

# 2. å®‰è£…PyTorchï¼ˆGPUç‰ˆæœ¬ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. å®‰è£…æ·±åº¦å­¦ä¹ åº“
pip install segmentation-models-pytorch
pip install mmsegmentation
pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.0/index.html

# 4. å®‰è£…å…¶ä»–ä¾èµ–
pip install opencv-python-headless>=4.8.0
pip install albumentations
pip install scikit-image
pip install rasterio
pip install spectral
pip install fastapi uvicorn
pip install streamlit
pip install redis
pip install psycopg2-binary
pip install minio

# 5. åˆ›å»ºé¡¹ç›®ç»“æ„
mkdir -p backend/algorithms/segmentation/models
mkdir -p backend/algorithms/segmentation/losses
mkdir -p backend/algorithms/tracking
mkdir -p backend/algorithms/fusion
mkdir -p data/datasets/road_segmentation
mkdir -p data/datasets/farmland_segmentation
mkdir -p models/segmentation
mkdir -p models/tracking
```

**æ•°æ®å‡†å¤‡**ï¼š
- [ ] æ”¶é›†é“è·¯å›¾åƒï¼ˆç‹­çª„ã€æ³¥æ³ã€æç«¯å¤©æ°”ï¼‰
- [ ] æ”¶é›†å†œç”°å›¾åƒï¼ˆä¸åŒä½œç‰©ã€ä¸åŒçŠ¶æ€ï¼‰
- [ ] ä½¿ç”¨LabelMeæˆ–CVATè¿›è¡Œæ ‡æ³¨
- [ ] æ•°æ®æ ¼å¼è½¬æ¢ï¼ˆCOCOæ ¼å¼ï¼‰

**è¯¦ç»†æµç¨‹ï¼š**

1. **å‡†å¤‡åŸå§‹æ•°æ®ç›®å½•**
   ```powershell
   # åˆ›å»ºåŸå§‹æ•°æ®ç›®å½•
   New-Item -ItemType Directory -Force -Path `
       "data\raw\roads\narrow", `
       "data\raw\roads\muddy", `
       "data\raw\roads\extreme_weather", `
       "data\raw\farmland\paddy", `
       "data\raw\farmland\wheat", `
       "data\raw\farmland\corn", `
       "data\raw\farmland\soybean"
   ```
   - é“è·¯æ•°æ®æ¥æºï¼šæ— äººæœºè‡ªé‡‡ã€å…¬å¼€æ•°æ®é›†ï¼ˆDeepGlobe Road Extractionã€Massachusetts Roadsã€Culane ç­‰ï¼‰
   - å†œç”°æ•°æ®æ¥æºï¼šè‡ªé‡‡ã€å¤šå…‰è°±æ•°æ®é›†ï¼ˆSentinel-2ã€Planet Labsï¼‰ã€å…¬å¼€æ•°æ®ï¼ˆHarvested Field Datasetï¼‰

2. **å›¾åƒæ”¶é›†å»ºè®®**
   - **ç‹­çª„é“è·¯**ï¼šæ‹æ‘„ä¹¡æ‘ã€å±±è·¯ã€æ–½å·¥é“è·¯ï¼Œå…³æ³¨è¾¹ç•Œæ¨¡ç³Šçš„æƒ…å†µ
   - **æ³¥æ³é“è·¯**ï¼šé›¨å­£ã€æ–½å·¥ç°åœºï¼Œæ³¨æ„æ°´å‘ã€åå…‰ã€æ³¥æµ†çº¹ç†
   - **æç«¯å¤©æ°”**ï¼šå¤œé—´ã€é›¾éœ¾ã€æš´é›¨/é›ªæ™¯ï¼Œå¯ä½¿ç”¨æ•°æ®å¢å¼ºæ¨¡æ‹Ÿï¼ˆæ·»åŠ é›¨é›ªæ»¤é•œï¼‰
   - **å†œç”°**ï¼šè¦†ç›–ä¸åŒä½œç‰©ã€ä¸åŒç”Ÿé•¿é˜¶æ®µï¼ˆæ’­ç§ã€æŠ½ç©—ã€æ”¶å‰²ï¼‰ã€ä¸åŒåœŸå£¤çŠ¶æ€ï¼ˆå¹²æ—±ã€ç§¯æ°´ï¼‰

3. **å®‰è£…æ ‡æ³¨å·¥å…·**
   - **LabelMeï¼ˆWindowsæœ¬åœ°ï¼‰**
     ```powershell
     # å»ºè®®ä½¿ç”¨ç‹¬ç«‹è™šæ‹Ÿç¯å¢ƒ
     conda create -n labelme python=3.10 -y
     conda activate labelme
     pip install labelme
     labelme
     ```
   - **CVATï¼ˆWebç‰ˆæœ¬ï¼‰**
     ```powershell
     git clone https://github.com/opencv/cvat.git
     cd cvat
     docker compose up -d
     # è®¿é—® http://localhost:8080
     ```
   - æ ‡æ³¨è§„èŒƒï¼š
     - é“è·¯ï¼šå¤šè¾¹å½¢æ–¹å¼æ²¿é“è·¯è¾¹ç¼˜æ ‡æ³¨
     - å†œç”°ï¼šç»˜åˆ¶ç”°å—è½®å»“ï¼Œå¯åˆ†ä½œç‰©ç±»å‹
     - ä¿ç•™ç±»åˆ«åç§°ä¸€è‡´ï¼ˆå¦‚ `road_narrow`, `road_muddy`, `farmland_rice`, `farmland_corn`ï¼‰

4. **å¯¼å‡ºæ ‡æ³¨æ•°æ®**
   - LabelMeï¼šå¯¼å‡º JSON æ–‡ä»¶ï¼ˆæ¯å¼ å›¾ä¸€ä¸ª JSONï¼‰
   - CVATï¼šåœ¨ä»»åŠ¡é¡µé¢é€‰æ‹© **Export Task -> COCO 1.0** æˆ– **LabelMe 3.0** æ ¼å¼
   - ç›®å½•ç¤ºä¾‹ï¼š
     ```
     data/raw/roads/narrow/
         img_001.jpg
         img_001.json
     data/raw/farmland/paddy/
         img_100.jpg
         img_100.json
     ```

5. **è½¬æ¢ä¸º COCO æ ¼å¼**
   - å®‰è£…è½¬æ¢å·¥å…·ï¼š
     ```powershell
     pip install labelme2coco
     ```
   - é“è·¯æ•°æ®è½¬æ¢ï¼š
     ```powershell
     labelme2coco data/raw/roads --output data/datasets/road_segmentation/coco.json
     ```
   - å†œç”°æ•°æ®è½¬æ¢ï¼š
     ```powershell
     labelme2coco data/raw/farmland --output data/datasets/farmland_segmentation/coco.json
     ```
   - å¦‚æœä½¿ç”¨ CVAT ç›´æ¥å¯¼å‡ºçš„ COCOï¼Œå¯è·³è¿‡æ­¤æ­¥éª¤ï¼Œç›´æ¥å°† `annotations/instances_default.json` æ”¾ç½®åˆ° `data/datasets/...` å¯¹åº”ç›®å½•ã€‚

6. **åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†**
   ```powershell
   python scripts/split_dataset.py `
       --input data/datasets/road_segmentation/coco.json `
       --output data/datasets/road_segmentation `
       --train-ratio 0.8 `
       --val-ratio 0.2
   ```
   - ç»“æœç›®å½•ç¤ºä¾‹ï¼š
     ```
     data/datasets/road_segmentation/
         train/images/
         train/labels/
         val/images/
         val/labels/
         coco_train.json
         coco_val.json
     ```

7. **æ•°æ®è´¨é‡è‡ªæ£€**
   - éšæœºæŠ½æ · 10% æ•°æ®ï¼Œåœ¨ LabelMe/CVAT ä¸­å¤æŸ¥
   - ç¡®ä¿æ¯å¼ å›¾è‡³å°‘åŒ…å«ä¸€ä¸ªç›®æ ‡
   - æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ç±»åˆ«æˆ–æ¼æ ‡
   - ä½¿ç”¨è„šæœ¬éªŒè¯ COCO JSON æ˜¯å¦å¯è§£æï¼š
     ```powershell
     python - <<'PY'
     import json
     from pathlib import Path
     path = Path("data/datasets/road_segmentation/coco_train.json")
     data = json.loads(path.read_text())
     print("Images:", len(data["images"]))
     print("Annotations:", len(data["annotations"]))
     print("Categories:", [c["name"] for c in data["categories"]])
     PY
     ```

å®Œæˆä»¥ä¸Šæ­¥éª¤åï¼Œå³å¯å‹¾é€‰æ•°æ®å‡†å¤‡æ¸…å•å¹¶è¿›å…¥æ¨¡å‹å¼€å‘é˜¶æ®µã€‚

#### Day 2-3: è¯­ä¹‰åˆ†å‰²æ¨¡å‹å¼€å‘
**ç›®æ ‡**ï¼šå®ç°é“è·¯åˆ†å‰²æ¨¡å‹

**å®æ–½æ­¥éª¤**ï¼š

1. **åˆ›å»ºæ¨¡å‹æ–‡ä»¶**
```powershell
# åˆ›å»ºæ¨¡å‹ç›®å½•
cd backend/algorithms/segmentation/models

# åˆ›å»ºDeepLabV3+æ¨¡å‹
# (ä»£ç è§å®Œæ•´æ–¹æ¡ˆæ–‡æ¡£)
```

2. **å®ç°æŸå¤±å‡½æ•°**
```powershell
cd backend/algorithms/segmentation/losses

# åˆ›å»ºç»„åˆæŸå¤±å‡½æ•°
# (ä»£ç è§å®Œæ•´æ–¹æ¡ˆæ–‡æ¡£)
```

3. **è®­ç»ƒè„šæœ¬**
```python
# scripts/train_road_segmentation.py
import torch
from torch.utils.data import DataLoader
from backend.algorithms.segmentation.models.deeplabv3_plus import AdvancedRoadSegmentation
from backend.algorithms.segmentation.losses.combined_loss import RoadSegmentationLoss
from data.datasets.road_segmentation import RoadSegmentationDataset

# åˆå§‹åŒ–æ¨¡å‹
model = AdvancedRoadSegmentation(num_classes=2, backbone='resnet50')
model = model.cuda()

# åˆå§‹åŒ–æŸå¤±å‡½æ•°
criterion = RoadSegmentationLoss()

# åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
train_dataset = RoadSegmentationDataset('data/datasets/road_segmentation/train')
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)

# è®­ç»ƒå¾ªç¯
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)

for epoch in range(100):
    for batch in train_loader:
        images, masks = batch
        images = images.cuda()
        masks = masks.cuda()
        
        # å‰å‘ä¼ æ’­
        outputs, weather_pred = model(images)
        
        # è®¡ç®—æŸå¤±
        loss, loss_dict = criterion(outputs, masks)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    scheduler.step()
    print(f"Epoch {epoch}, Loss: {loss.item()}")
```

#### Day 4: é“è·¯è¯†åˆ«ä¼˜åŒ–
**ç›®æ ‡**ï¼šé’ˆå¯¹å›°éš¾åœºæ™¯ä¼˜åŒ–æ¨¡å‹

**ä»»åŠ¡**ï¼š
- [ ] å®ç°æ•°æ®å¢å¼ºï¼ˆç‹­çª„é“è·¯ã€æ³¥æ³ã€æç«¯å¤©æ°”ï¼‰
- [ ] è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡
- [ ] å¾®è°ƒæ¨¡å‹è¶…å‚æ•°
- [ ] æµ‹è¯•ä¸åŒåœºæ™¯çš„å‡†ç¡®ç‡

#### Day 5: å†œç”°è¯†åˆ«å¼€å‘
**ç›®æ ‡**ï¼šå®ç°å†œç”°åˆ†å‰²æ¨¡å‹

**ä»»åŠ¡**ï¼š
- [ ] å®ç°U-Net++æ¨¡å‹
- [ ] å¤šå…‰è°±æ•°æ®å¤„ç†
- [ ] ä½œç‰©ç±»å‹åˆ†ç±»
- [ ] è®­ç»ƒå†œç”°åˆ†å‰²æ¨¡å‹

### ç¬¬8å‘¨ï¼ˆ5ä¸ªå·¥ä½œæ—¥ï¼‰

#### Day 1-2: ç›®æ ‡è·Ÿè¸ªå®ç°
**ç›®æ ‡**ï¼šå®ç°DeepSORTè·Ÿè¸ªç®—æ³•

**å®æ–½æ­¥éª¤**ï¼š

1. **å®‰è£…ä¾èµ–**
```powershell
pip install filterpy
pip install scikit-learn
pip install lap  # åŒˆç‰™åˆ©ç®—æ³•
```

2. **å®ç°DeepSORT**
```python
# backend/algorithms/tracking/deepsort.py
# (ä»£ç è§å®Œæ•´æ–¹æ¡ˆæ–‡æ¡£)
```

3. **æµ‹è¯•è·Ÿè¸ª**
```python
# scripts/test_tracking.py
from backend.algorithms.tracking.deepsort import DeepSORTTracker
from ultralytics import YOLO

# åˆå§‹åŒ–æ£€æµ‹å™¨å’Œè·Ÿè¸ªå™¨
detector = YOLO('yolov8n.pt')
tracker = DeepSORTTracker()

# å¤„ç†è§†é¢‘
cap = cv2.VideoCapture('test_video.mp4')
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # æ£€æµ‹
    detections = detector(frame)
    
    # è·Ÿè¸ª
    tracks = tracker.update(detections)
    
    # ç»˜åˆ¶ç»“æœ
    for track in tracks:
        cv2.rectangle(frame, track.bbox, (0, 255, 0), 2)
        cv2.putText(frame, f"ID: {track.id}", 
                   (track.bbox[0], track.bbox[1]-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    cv2.imshow('Tracking', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
```

#### Day 3-4: ä¼ æ„Ÿå™¨èåˆ
**ç›®æ ‡**ï¼šå®ç°å¤šä¼ æ„Ÿå™¨æ•°æ®å¤„ç†

**ä»»åŠ¡**ï¼š
- [ ] å¤šå…‰è°±æ•°æ®å¤„ç†ï¼ˆNDVIã€EVIè®¡ç®—ï¼‰
- [ ] çº¢å¤–å›¾åƒå¤„ç†
- [ ] å¤šæ¨¡æ€èåˆæ¨¡å‹
- [ ] èåˆæ•ˆæœæµ‹è¯•

#### Day 5: æ€§èƒ½æµ‹è¯•ä¸ç³»ç»Ÿé›†æˆ
**ç›®æ ‡**ï¼šå®Œæˆæ€§èƒ½æµ‹è¯•å’Œç³»ç»Ÿé›†æˆ

**ä»»åŠ¡**ï¼š
- [ ] å®ç°æ€§èƒ½è¯„ä¼°æŒ‡æ ‡
- [ ] è¿è¡ŒåŸºå‡†æµ‹è¯•
- [ ] APIé›†æˆ
- [ ] Streamlitç•Œé¢é›†æˆ
- [ ] ç³»ç»Ÿæµ‹è¯•

---

## ğŸ”§ å¿«é€Ÿå¯åŠ¨å‘½ä»¤

### å¼€å‘ç¯å¢ƒå¯åŠ¨

```powershell
# 1. æ¿€æ´»ç¯å¢ƒ
conda activate drone_vision_advanced

# 2. å¯åŠ¨FastAPIåç«¯
cd backend/api
uvicorn main:app --reload --port 8000

# 3. å¯åŠ¨Streamlitå‰ç«¯ï¼ˆæ–°ç»ˆç«¯ï¼‰
cd frontend/streamlit_app
streamlit run app.py --server.port 8501

# 4. å¯åŠ¨ç®—æ³•æœåŠ¡ï¼ˆæ–°ç»ˆç«¯ï¼‰
cd backend/algorithms
python segmentation/inference.py
```

### Dockerå¯åŠ¨

```powershell
# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

---

## ğŸ“Š æ€§èƒ½ç›®æ ‡

### è¯­ä¹‰åˆ†å‰²
- **mIoU**: > 0.85ï¼ˆé“è·¯ï¼‰ï¼Œ> 0.80ï¼ˆå†œç”°ï¼‰
- **Pixel Accuracy**: > 0.90
- **FPS**: > 15ï¼ˆGPUï¼‰ï¼Œ> 5ï¼ˆCPUï¼‰

### ç›®æ ‡è·Ÿè¸ª
- **MOTA**: > 0.75
- **MOTP**: > 0.80
- **ID Switches**: < 5%ï¼ˆæ¯100å¸§ï¼‰

### ç³»ç»Ÿæ€§èƒ½
- **APIå“åº”æ—¶é—´**: < 500ms
- **å¹¶å‘å¤„ç†**: > 10 requests/s
- **å†…å­˜å ç”¨**: < 4GBï¼ˆå•æœåŠ¡ï¼‰

---

## ğŸ› å¸¸è§é—®é¢˜è§£å†³

### é—®é¢˜1ï¼šCUDAå†…å­˜ä¸è¶³
**è§£å†³æ–¹æ¡ˆ**ï¼š
- å‡å°batch size
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼‰
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

### é—®é¢˜2ï¼šæ¨¡å‹è®­ç»ƒä¸æ”¶æ•›
**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥å­¦ä¹ ç‡ï¼ˆå°è¯•1e-4, 1e-5ï¼‰
- æ£€æŸ¥æ•°æ®æ ‡æ³¨è´¨é‡
- å¢åŠ æ•°æ®å¢å¼º
- ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹

### é—®é¢˜3ï¼šæ¨ç†é€Ÿåº¦æ…¢
**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨æ¨¡å‹é‡åŒ–ï¼ˆINT8ï¼‰
- ä½¿ç”¨TensorRTä¼˜åŒ–
- å‡å°è¾“å…¥å›¾åƒå°ºå¯¸
- ä½¿ç”¨æ›´è½»é‡çš„backbone

---

## âœ… å®Œæˆæ ‡å‡†

### ç®—æ³•å®Œæˆæ ‡å‡†
- [ ] é“è·¯åˆ†å‰²mIoU > 0.85
- [ ] å†œç”°åˆ†å‰²mIoU > 0.80
- [ ] è·Ÿè¸ªMOTA > 0.75
- [ ] æ¨ç†é€Ÿåº¦ > 15 FPSï¼ˆGPUï¼‰

### ç³»ç»Ÿå®Œæˆæ ‡å‡†
- [ ] APIæœåŠ¡æ­£å¸¸è¿è¡Œ
- [ ] å‰ç«¯ç•Œé¢åŠŸèƒ½å®Œæ•´
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡
- [ ] æ–‡æ¡£å®Œæ•´

---

**æŒ‰ç…§æ­¤æ­¥éª¤æ‰§è¡Œï¼Œç¡®ä¿ç¬¬7-8å‘¨ä»»åŠ¡é«˜è´¨é‡å®Œæˆï¼** ğŸš€

