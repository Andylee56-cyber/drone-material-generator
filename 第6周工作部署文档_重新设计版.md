# ç¬¬6å‘¨å·¥ä½œéƒ¨ç½²æ–‡æ¡£ - æ— äººæœºç´ æå¤šè§’åº¦ç”Ÿæˆä¸åˆ†æç³»ç»Ÿ
## é‡æ–°è®¾è®¡ç‰ˆ - å•å›¾è¾“å…¥â†’å¤šè§’åº¦ç”Ÿæˆâ†’8ç»´é›·è¾¾å›¾åˆ†æ

> **æ ¸å¿ƒåŠŸèƒ½**: è¾“å…¥ä¸€å¼ å›¾ç‰‡ï¼Œç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆå¤šè§’åº¦ç´ æï¼Œå¹¶ç”Ÿæˆ8ç»´åº¦é›·è¾¾å›¾å¯è§†åŒ–

---

## ğŸ“‹ ç³»ç»ŸåŠŸèƒ½è¯´æ˜

### æ ¸å¿ƒåŠŸèƒ½æµç¨‹
```
è¾“å…¥å•å¼ å›¾ç‰‡ 
  â†“
è‡ªåŠ¨ç”Ÿæˆå¤šè§’åº¦ç´ æï¼ˆæ—‹è½¬ã€ç¿»è½¬ã€äº®åº¦ã€å¯¹æ¯”åº¦ç­‰å˜æ¢ï¼‰
  â†“
8ç»´åº¦è´¨é‡åˆ†æï¼ˆå›¾ç‰‡æ•°æ®é‡ã€å…‰ç…§è´¨é‡ã€ç›®æ ‡å°ºå¯¸ç­‰ï¼‰
  â†“
ç”Ÿæˆ8ç»´åº¦é›·è¾¾å›¾ï¼ˆåœ†å½¢å¯è§†åŒ–å›¾è¡¨ï¼‰
  â†“
è¾“å‡ºåˆ†ææŠ¥å‘Š
```

### 8ä¸ªåˆ†æç»´åº¦
1. **å›¾ç‰‡æ•°æ®é‡** - åŸºäºåˆ†è¾¨ç‡å’Œæ–‡ä»¶å¤§å°
2. **æ‹æ‘„å…‰ç…§è´¨é‡** - åŸºäºäº®åº¦ã€å¯¹æ¯”åº¦ã€æ›å…‰
3. **ç›®æ ‡å°ºå¯¸** - åŸºäºYOLOæ£€æµ‹çš„ç›®æ ‡å¹³å‡å°ºå¯¸
4. **ç›®æ ‡å®Œæ•´æ€§** - åŸºäºç›®æ ‡æ˜¯å¦è¢«è£å‰ªæˆ–é®æŒ¡
5. **æ•°æ®å‡è¡¡åº¦** - åŸºäºä¸åŒç±»åˆ«ç›®æ ‡çš„åˆ†å¸ƒå‡è¡¡æ€§
6. **äº§å“ä¸°å¯Œåº¦** - åŸºäºæ£€æµ‹åˆ°çš„ç›®æ ‡ç±»åˆ«æ•°é‡
7. **ç›®æ ‡å¯†é›†åº¦** - åŸºäºå•ä½é¢ç§¯å†…çš„ç›®æ ‡æ•°é‡
8. **åœºæ™¯å¤æ‚åº¦** - åŸºäºèƒŒæ™¯å¤æ‚åº¦ã€çº¹ç†ä¸°å¯Œåº¦

---

## ğŸ“ ç¬¬ä¸€æ­¥ï¼šå»ºç«‹å®Œæ•´çš„ç›®å½•ç»“æ„

### 1.1 æ‰“å¼€PowerShellå¹¶å®šä½åˆ°é¡¹ç›®ç›®å½•

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd D:\mlflow_learning_project

# éªŒè¯å½“å‰ä½ç½®
pwd
```

**é¢„æœŸè¾“å‡º**:
```
Path
----
D:\mlflow_learning_project
```

### 1.2 åˆ›å»ºæ‰€æœ‰å¿…éœ€çš„ç›®å½•ç»“æ„

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# åˆ›å»ºæ‰€æœ‰å¿…éœ€ç›®å½•
New-Item -ItemType Directory -Path "agents","app\web","scripts","reports","temp_uploads","test_images","generated_materials" -Force | Out-Null

# éªŒè¯ç›®å½•åˆ›å»º
Get-ChildItem -Directory | Select-Object Name | Format-Table -AutoSize
```

**é¢„æœŸè¾“å‡º**:
```
Name
----
agents
app
generated_materials
reports
scripts
temp_uploads
test_images
```

---

## ğŸ”§ ç¬¬äºŒæ­¥ï¼šç¯å¢ƒé…ç½®ä¸ä¾èµ–å®‰è£…

### 2.1 æ¿€æ´»Condaç¯å¢ƒ

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# æ¿€æ´»ç¯å¢ƒ
conda activate uav_adv

# éªŒè¯ç¯å¢ƒï¼ˆå‘½ä»¤æç¤ºç¬¦å‰åº”æ˜¾ç¤º (uav_adv)ï¼‰
python --version
```

### 2.2 å®‰è£…ä¾èµ–åŒ…

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install ultralytics==8.2.74
pip install plotly>=5.23.0
pip install streamlit>=1.37.1
pip install opencv-python-headless==4.9.0.80
pip install pillow>=9.5.0
pip install numpy>=1.23.5
pip install pandas>=2.0.3

# éªŒè¯å®‰è£…
python -c "import ultralytics, plotly, streamlit, cv2, PIL; print('âœ… æ‰€æœ‰ä¾èµ–OK')"
```

---

## ğŸ§± ç¬¬ä¸‰æ­¥ï¼šåˆ›å»º/æ›´æ–°æ ¸å¿ƒ Python æ–‡ä»¶ï¼ˆåœ¨ PowerShell ä¸­åˆ›å»ºï¼‰

> **è¯´æ˜**ï¼šä»¥ä¸‹å‘½ä»¤å¿…é¡»åœ¨ PowerShell ä¸­æ‰§è¡Œï¼Œç¡®ä¿æ¯ä¸ª `.py` æ–‡ä»¶éƒ½åœ¨æœ¬åœ°åˆ›å»ºï¼Œä¾¿äºè‡ªè¡Œç®¡ç†ã€‚

### 3.1 åˆ›å»º `agents\image_multi_angle_generator.py`

```powershell
@'
""" 
å›¾ç‰‡å¤šè§’åº¦ç”Ÿæˆå™¨ 
Image Multi-Angle Generator 
ä»å•å¼ è¾“å…¥å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦çš„ç´ æå›¾ç‰‡ 
"""

import numpy as np
import cv2
from PIL import Image
from pathlib import Path
from typing import List, Dict, Optional
import random
from datetime import datetime


class ImageMultiAngleGenerator:
    """å›¾ç‰‡å¤šè§’åº¦ç”Ÿæˆå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.supported_formats = {'.jpg', '.jpeg', '.png', '.bmp'}

    def generate_multi_angle_images(
        self,
        input_image_path: str,
        output_dir: str,
        num_generations: int = 8,
        transformations: List[str] = None
    ) -> Dict:
        """
        ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æ

        å‚æ•°:
            input_image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            num_generations: ç”Ÿæˆæ•°é‡
            transformations: å˜æ¢ç±»å‹åˆ—è¡¨ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å˜æ¢ï¼‰

        è¿”å›:
            ç”Ÿæˆç»“æœå­—å…¸
        """
        input_path = Path(input_image_path)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        if not input_path.exists():
            raise FileNotFoundError(f"è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {input_image_path}")

        # è¯»å–åŸå§‹å›¾ç‰‡
        img = cv2.imread(str(input_path))
        if img is None:
            pil_img = Image.open(input_path)
            img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

        h, w = img.shape[:2]

        if transformations is None:
            transformations = [
                'original', 'rotate_15', 'rotate_-15', 'rotate_30',
                'flip_horizontal', 'flip_vertical',
                'brightness_up', 'brightness_down',
                'contrast_up', 'contrast_down',
                'saturation_up', 'saturation_down',
                'blur_slight', 'sharp',
                'crop_center', 'crop_corner',
                'zoom_in', 'zoom_out',
                'perspective', 'noise'
            ]

        if num_generations > len(transformations):
            selected_transforms = transformations + random.sample(
                transformations,
                num_generations - len(transformations)
            )
        else:
            selected_transforms = random.sample(transformations, num_generations)

        generated_files = []
        metadata = []

        for idx, transform_type in enumerate(selected_transforms, 1):
            try:
                transformed_img = self._apply_transformation(img, transform_type, h, w)
                output_filename = f"generated_{idx:03d}_{transform_type}.jpg"
                output_file = output_path / output_filename
                cv2.imwrite(str(output_file), transformed_img, [cv2.IMWRITE_JPEG_QUALITY, 95])

                generated_files.append(str(output_file))
                metadata.append({
                    'index': idx,
                    'original_path': str(input_path),
                    'generated_path': str(output_file),
                    'transformation': transform_type,
                    'filename': output_filename
                })
            except Exception as e:
                print(f"âš ï¸ ç”Ÿæˆå¤±è´¥ {transform_type}: {e}")
                continue

        metadata_file = output_path / f"generation_metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        import json
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump({
                'generation_time': datetime.now().isoformat(),
                'original_image': str(input_path),
                'output_dir': str(output_path),
                'num_requested': num_generations,
                'num_generated': len(generated_files),
                'generated_images': metadata
            }, f, ensure_ascii=False, indent=2)

        return {
            'success': True,
            'original_image': str(input_path),
            'output_dir': str(output_path),
            'num_generated': len(generated_files),
            'generated_files': generated_files,
            'metadata_file': str(metadata_file)
        }

    def _apply_transformation(self, img: np.ndarray, transform_type: str, h: int, w: int) -> np.ndarray:
        """åº”ç”¨æŒ‡å®šçš„å˜æ¢"""
        result = img.copy()

        if transform_type == 'original':
            return result
        elif transform_type == 'rotate_15':
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, 15, 1.0)
            result = cv2.warpAffine(result, M, (w, h), borderValue=(128, 128, 128))
        elif transform_type == 'rotate_-15':
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, -15, 1.0)
            result = cv2.warpAffine(result, M, (w, h), borderValue=(128, 128, 128))
        elif transform_type == 'rotate_30':
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, 30, 1.0)
            result = cv2.warpAffine(result, M, (w, h), borderValue=(128, 128, 128))
        elif transform_type == 'flip_horizontal':
            result = cv2.flip(result, 1)
        elif transform_type == 'flip_vertical':
            result = cv2.flip(result, 0)
        elif transform_type == 'brightness_up':
            result = cv2.convertScaleAbs(result, alpha=1.2, beta=20)
        elif transform_type == 'brightness_down':
            result = cv2.convertScaleAbs(result, alpha=0.8, beta=-20)
        elif transform_type == 'contrast_up':
            result = cv2.convertScaleAbs(result, alpha=1.3, beta=0)
        elif transform_type == 'contrast_down':
            result = cv2.convertScaleAbs(result, alpha=0.7, beta=0)
        elif transform_type == 'saturation_up':
            hsv = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)
            hsv[:, :, 1] = cv2.multiply(hsv[:, :, 1], 1.3)
            result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        elif transform_type == 'saturation_down':
            hsv = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)
            hsv[:, :, 1] = cv2.multiply(hsv[:, :, 1], 0.7)
            result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        elif transform_type == 'blur_slight':
            result = cv2.GaussianBlur(result, (5, 5), 0)
        elif transform_type == 'sharp':
            kernel = np.array([[-1, -1, -1], [-1,  9, -1], [-1, -1, -1]])
            result = cv2.filter2D(result, -1, kernel)
        elif transform_type == 'crop_center':
            crop_size = min(h, w) * 0.8
            x = int((w - crop_size) / 2)
            y = int((h - crop_size) / 2)
            result = result[y:int(y+crop_size), x:int(x+crop_size)]
            result = cv2.resize(result, (w, h))
        elif transform_type == 'crop_corner':
            crop_size = min(h, w) * 0.8
            result = result[0:int(crop_size), 0:int(crop_size)]
            result = cv2.resize(result, (w, h))
        elif transform_type == 'zoom_in':
            M = cv2.getRotationMatrix2D((w/2, h/2), 0, 1.2)
            result = cv2.warpAffine(result, M, (w, h))
        elif transform_type == 'zoom_out':
            M = cv2.getRotationMatrix2D((w/2, h/2), 0, 0.8)
            result = cv2.warpAffine(result, M, (w, h), borderValue=(128, 128, 128))
        elif transform_type == 'perspective':
            pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])
            pts2 = np.float32([[w*0.1, h*0.1], [w*0.9, h*0.1], [0, h], [w, h]])
            M = cv2.getPerspectiveTransform(pts1, pts2)
            result = cv2.warpPerspective(result, M, (w, h))
        elif transform_type == 'noise':
            noise = np.random.randint(0, 25, result.shape, dtype=np.uint8)
            result = cv2.add(result, noise)

        return result


if __name__ == "__main__":
    generator = ImageMultiAngleGenerator()
    result = generator.generate_multi_angle_images(
        input_image_path="test.jpg",
        output_dir="generated",
        num_generations=8
    )
    print(f"ç”Ÿæˆäº† {result['num_generated']} å¼ å›¾ç‰‡")
'@ | Set-Content "agents\image_multi_angle_generator.py" -Encoding UTF8
```

### 3.2 åˆ›å»º `scripts\generate_from_single_image.py`

```powershell
@'
"""
ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æå¹¶åˆ†æ
Generate Multi-Angle Materials from Single Image and Analyze
"""

import argparse
import json
from pathlib import Path
import sys

project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

from agents.image_multi_angle_generator import ImageMultiAngleGenerator
from agents.image_quality_analyzer import ImageQualityAnalyzer
from agents.material_generator_agent import MaterialGeneratorAgent


def main():
    parser = argparse.ArgumentParser(description="ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æå¹¶åˆ†æ")
    parser.add_argument("--input-image", type=str, required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--output-dir", type=str, default="generated_materials", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--num-generations", type=int, default=8, help="ç”Ÿæˆå›¾ç‰‡æ•°é‡")
    parser.add_argument("--analyze", action="store_true", help="ç”Ÿæˆåè‡ªåŠ¨åˆ†æ")
    parser.add_argument("--yolo-model", type=str, default=None, help="YOLOæ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    args = parser.parse_args()

    input_path = Path(args.input_image)
    if not input_path.exists():
        print(f"âŒ è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {args.input_image}")
        return

    print("=" * 60)
    print("ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æ")
    print("=" * 60)
    print(f"è¾“å…¥å›¾ç‰‡: {args.input_image}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ç”Ÿæˆæ•°é‡: {args.num_generations}")
    print("=" * 60)

    print("\næ­¥éª¤1: ç”Ÿæˆå¤šè§’åº¦å›¾ç‰‡...")
    generator = ImageMultiAngleGenerator()
    try:
        result = generator.generate_multi_angle_images(
            input_image_path=str(input_path),
            output_dir=args.output_dir,
            num_generations=args.num_generations
        )
        if result['success']:
            print(f"âœ… æˆåŠŸç”Ÿæˆ {result['num_generated']} å¼ å›¾ç‰‡")
## ğŸ“ ç¬¬ä¸‰æ­¥ï¼šéªŒè¯æ ¸å¿ƒæ–‡ä»¶

### 3.1 æ£€æŸ¥æ ¸å¿ƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# æ£€æŸ¥æ–‡ä»¶
$files = @(
    "agents\__init__.py",
    "agents\image_quality_analyzer.py",
    "agents\image_multi_angle_generator.py",
    "agents\material_generator_agent.py",
    "app\web\material_generator_app.py",
    "scripts\generate_from_single_image.py"
)

foreach ($file in $files) {
    if (Test-Path $file) {
        Write-Host "âœ… $file" -ForegroundColor Green
    } else {
        Write-Host "âŒ ç¼ºå¤±: $file" -ForegroundColor Red
    }
}
```

### 3.2 éªŒè¯æ¨¡å—å¯¼å…¥

**æ‰§è¡Œå‘½ä»¤**:

```powershell
python -c "
import sys
sys.path.insert(0, '.')
from agents.image_multi_angle_generator import ImageMultiAngleGenerator
from agents.image_quality_analyzer import ImageQualityAnalyzer
from agents.material_generator_agent import MaterialGeneratorAgent
print('âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ')
"
```

---

## ğŸ§ª ç¬¬å››æ­¥ï¼šæµ‹è¯•å¤šè§’åº¦ç”ŸæˆåŠŸèƒ½

### 4.1 å‡†å¤‡æµ‹è¯•å›¾ç‰‡

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# æ–¹æ³•1: ä»æŒ‡å®šç›®å½•å¤åˆ¶
$sourceImage = Get-ChildItem "D:\ç½‘ä¸Šç´ æå›¾ç‰‡\*.jpg" | Select-Object -First 1
if ($sourceImage) {
    Copy-Item $sourceImage.FullName -Destination "test_images\test_input.jpg" -Force
    Write-Host "âœ… å·²å¤åˆ¶æµ‹è¯•å›¾ç‰‡: $($sourceImage.Name)" -ForegroundColor Green
}

# æ–¹æ³•2: æ‰“å¼€ç›®å½•æ‰‹åŠ¨å¤åˆ¶
explorer test_images

# éªŒè¯å›¾ç‰‡å­˜åœ¨
if (Test-Path "test_images\test_input.jpg") {
    $img = Get-Item "test_images\test_input.jpg"
    Write-Host "âœ… æµ‹è¯•å›¾ç‰‡: $($img.Name) ($([math]::Round($img.Length/1KB, 2)) KB)" -ForegroundColor Green
} else {
    Write-Host "âŒ è¯·å…ˆå‡†å¤‡æµ‹è¯•å›¾ç‰‡" -ForegroundColor Red
}
```

### 4.2 æµ‹è¯•å¤šè§’åº¦ç”Ÿæˆ

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# æµ‹è¯•ç”Ÿæˆ8å¼ å¤šè§’åº¦å›¾ç‰‡
python -c "
import sys
sys.path.insert(0, '.')
from agents.image_multi_angle_generator import ImageMultiAngleGenerator

generator = ImageMultiAngleGenerator()
result = generator.generate_multi_angle_images(
    input_image_path='test_images/test_input.jpg',
    output_dir='test_generated',
    num_generations=8
)

print('=' * 60)
print('å¤šè§’åº¦ç”Ÿæˆæµ‹è¯•ç»“æœ')
print('=' * 60)
print(f'è¾“å…¥å›¾ç‰‡: test_images/test_input.jpg')
print(f'ç”Ÿæˆæ•°é‡: {result[\"num_generated\"]} å¼ ')
print(f'è¾“å‡ºç›®å½•: {result[\"output_dir\"]}')
print('=' * 60)
print('âœ… ç”Ÿæˆæµ‹è¯•å®Œæˆ')
"
```

**é¢„æœŸè¾“å‡º**:
```
============================================================
å¤šè§’åº¦ç”Ÿæˆæµ‹è¯•ç»“æœ
============================================================
è¾“å…¥å›¾ç‰‡: test_images/test_input.jpg
ç”Ÿæˆæ•°é‡: 8 å¼ 
è¾“å‡ºç›®å½•: test_generated
============================================================
âœ… ç”Ÿæˆæµ‹è¯•å®Œæˆ
```

### 4.3 æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡
if (Test-Path "test_generated") {
    $generated = Get-ChildItem "test_generated\generated_*.jpg"
    Write-Host "`nç”Ÿæˆçš„å›¾ç‰‡:" -ForegroundColor Cyan
    $generated | ForEach-Object {
        Write-Host "  - $($_.Name) ($([math]::Round($_.Length/1KB, 2)) KB)" -ForegroundColor Green
    }
    
    # æ‰“å¼€ç›®å½•æŸ¥çœ‹
    explorer test_generated
}
```

---

## ğŸš€ ç¬¬äº”æ­¥ï¼šæµ‹è¯•å®Œæ•´æµç¨‹ï¼ˆç”Ÿæˆ+åˆ†æï¼‰

### 5.1 æ‰§è¡Œå®Œæ•´æµç¨‹æµ‹è¯•

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# ä½¿ç”¨è„šæœ¬æ‰§è¡Œå®Œæ•´æµç¨‹
python scripts\generate_from_single_image.py `
  --input-image "test_images\test_input.jpg" `
  --output-dir "test_complete" `
  --num-generations 8 `
  --analyze
```

**é¢„æœŸè¾“å‡º**:
```
============================================================
ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æå¹¶åˆ†æ
============================================================
è¾“å…¥å›¾ç‰‡: test_images\test_input.jpg
è¾“å‡ºç›®å½•: test_complete
ç”Ÿæˆæ•°é‡: 8
============================================================

æ­¥éª¤1: ç”Ÿæˆå¤šè§’åº¦å›¾ç‰‡...
âœ… æˆåŠŸç”Ÿæˆ 8 å¼ å›¾ç‰‡
è¾“å‡ºç›®å½•: test_complete

æ­¥éª¤2: åˆ†æç”Ÿæˆçš„å›¾ç‰‡...
æ­£åœ¨åˆå§‹åŒ–åˆ†æå™¨...
æ­£åœ¨åˆ†æå›¾ç‰‡ 1/8...
...
âœ… åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åˆ°: test_complete\analysis_result_xxx.json
å¹³å‡è´¨é‡: 82.35%

âœ… å¤„ç†å®Œæˆï¼
```

### 5.2 éªŒè¯åˆ†æç»“æœ

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# æŸ¥çœ‹åˆ†æç»“æœ
python -c "
import json
from pathlib import Path

result_file = list(Path('test_complete').glob('analysis_result_*.json'))[0]
with open(result_file, 'r', encoding='utf-8') as f:
    data = json.load(f)

print('=' * 60)
print('åˆ†æç»“æœéªŒè¯')
print('=' * 60)
print(f'åˆ†æå›¾ç‰‡æ•°: {data[\"analysis\"][\"total_images\"]}')
print(f'æ•´ä½“è´¨é‡: {data[\"recommendations\"][\"overall_quality\"]:.2f}%')
print('\nå¹³å‡ç»´åº¦å¾—åˆ†:')
for dim, score in data['analysis']['average_scores'].items():
    print(f'  {dim:20s}: {score:6.2f}%')
print('=' * 60)
"
```

---

## ğŸŒ ç¬¬å…­æ­¥ï¼šå¯åŠ¨Webç•Œé¢

### 6.1 å¯åŠ¨Webåº”ç”¨

**æ‰§è¡Œå‘½ä»¤**:

```powershell
# å¯åŠ¨Streamlitåº”ç”¨
conda activate uav_adv
streamlit run app\web\material_generator_app.py --server.port 8502

# è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
start http://localhost:8502
```

**é¢„æœŸè¾“å‡º**:
```
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8502
  Network URL: http://192.168.x.x:8502
```

### 6.2 ä½¿ç”¨Webç•Œé¢

**æ“ä½œæ­¥éª¤**:

1. **ä¸Šä¼ å›¾ç‰‡**:
   - åœ¨æµè§ˆå™¨ä¸­ç‚¹å‡»"ä¸Šä¼ ä¸€å¼ æ— äººæœºå›¾ç‰‡"
   - é€‰æ‹©ä½ çš„æµ‹è¯•å›¾ç‰‡ï¼ˆå¦‚ `test_images\test_input.jpg`ï¼‰

2. **è®¾ç½®å‚æ•°**:
   - åœ¨ä¾§è¾¹æ è®¾ç½®"ç”Ÿæˆå›¾ç‰‡æ•°é‡"ï¼ˆé»˜è®¤8å¼ ï¼‰
   - å‹¾é€‰"ç”Ÿæˆåè‡ªåŠ¨åˆ†æ"

3. **ç”Ÿæˆå’Œåˆ†æ**:
   - ç‚¹å‡»"ğŸš€ ç”Ÿæˆå¤šè§’åº¦ç´ æå¹¶åˆ†æ"æŒ‰é’®
   - ç­‰å¾…å¤„ç†å®Œæˆï¼ˆçº¦30-60ç§’ï¼‰

4. **æŸ¥çœ‹ç»“æœ**:
   - æŸ¥çœ‹ç”Ÿæˆçš„å¤šè§’åº¦ç´ æå›¾ç‰‡ç½‘æ ¼
   - æŸ¥çœ‹8ç»´åº¦é›·è¾¾å›¾ï¼ˆåœ†å½¢å›¾è¡¨ï¼‰
   - æŸ¥çœ‹ç»´åº¦å¾—åˆ†è¯¦æƒ…è¡¨æ ¼
   - æŸ¥çœ‹ç´ æè´¨é‡è¯„ä¼°è¡¨æ ¼

---

## ğŸ“Š ç¬¬ä¸ƒæ­¥ï¼šéªŒè¯é›·è¾¾å›¾æ˜¾ç¤º

### 7.1 æ£€æŸ¥é›·è¾¾å›¾æ˜¯å¦æ­£ç¡®æ˜¾ç¤º

**åœ¨Webç•Œé¢ä¸­éªŒè¯**:

- [ ] é›·è¾¾å›¾æ˜¯åœ†å½¢/å¤šè¾¹å½¢ï¼ˆä¸æ˜¯æ¡å½¢å›¾ï¼‰
- [ ] æ˜¾ç¤º8ä¸ªç»´åº¦
- [ ] æ¯ä¸ªç»´åº¦éƒ½æœ‰æ•°å€¼ï¼ˆ0-100%ï¼‰
- [ ] å›¾è¡¨æœ‰é¢œè‰²å¡«å……
- [ ] æ˜¾ç¤ºå›¾ä¾‹å’Œæ ‡é¢˜

### 7.2 éªŒè¯æ•°æ®å‡†ç¡®æ€§

**æ‰§è¡Œå‘½ä»¤éªŒè¯**:

```powershell
# éªŒè¯åˆ†ææ•°æ®çš„å®Œæ•´æ€§
python -c "
import sys
sys.path.insert(0, '.')
from agents.image_quality_analyzer import ImageQualityAnalyzer

analyzer = ImageQualityAnalyzer()
result = analyzer.analyze_single_image('test_images/test_input.jpg')

dimensions = ['å›¾ç‰‡æ•°æ®é‡', 'æ‹æ‘„å…‰ç…§è´¨é‡', 'ç›®æ ‡å°ºå¯¸', 'ç›®æ ‡å®Œæ•´æ€§', 
              'æ•°æ®å‡è¡¡åº¦', 'äº§å“ä¸°å¯Œåº¦', 'ç›®æ ‡å¯†é›†åº¦', 'åœºæ™¯å¤æ‚åº¦']

print('=' * 60)
print('ç»´åº¦æ•°æ®éªŒè¯')
print('=' * 60)
for dim in dimensions:
    if dim in result:
        print(f'âœ… {dim:20s}: {result[dim]:6.2f}%')
    else:
        print(f'âŒ {dim:20s}: ç¼ºå¤±')
print('=' * 60)
"
```

---

## ğŸ¯ å®Œæ•´å·¥ä½œæµç¨‹æ€»ç»“

### æ—¥å¸¸ä½¿ç”¨æµç¨‹

1. **å‡†å¤‡è¾“å…¥å›¾ç‰‡**:
   ```powershell
   # å°†å›¾ç‰‡æ”¾åˆ°test_imagesç›®å½•
   Copy-Item "D:\ä½ çš„å›¾ç‰‡\image.jpg" -Destination "test_images\input.jpg"
   ```

2. **å¯åŠ¨Webç•Œé¢**:
   ```powershell
   streamlit run app\web\material_generator_app.py --server.port 8502
   ```

3. **åœ¨Webç•Œé¢æ“ä½œ**:
   - ä¸Šä¼ å›¾ç‰‡
   - è®¾ç½®ç”Ÿæˆæ•°é‡
   - ç‚¹å‡»ç”ŸæˆæŒ‰é’®
   - æŸ¥çœ‹é›·è¾¾å›¾å’Œåˆ†æç»“æœ

4. **æŸ¥çœ‹ç”Ÿæˆç»“æœ**:
   ```powershell
   # æ‰“å¼€ç”Ÿæˆç›®å½•
   explorer generated_materials
   ```

### å‘½ä»¤è¡Œä½¿ç”¨æµç¨‹

```powershell
# ä¸€é”®ç”Ÿæˆå’Œåˆ†æ
python scripts\generate_from_single_image.py `
  --input-image "test_images\input.jpg" `
  --output-dir "output" `
  --num-generations 8 `
  --analyze
```

---

## âœ… éªŒæ”¶æ£€æŸ¥æ¸…å•

### åŠŸèƒ½éªŒæ”¶
- [ ] èƒ½å¤Ÿä¸Šä¼ å•å¼ å›¾ç‰‡
- [ ] èƒ½å¤Ÿç”Ÿæˆå¤šè§’åº¦ç´ æï¼ˆè‡³å°‘8å¼ ï¼‰
- [ ] èƒ½å¤Ÿè‡ªåŠ¨è¿›è¡Œ8ç»´åº¦åˆ†æ
- [ ] èƒ½å¤Ÿæ˜¾ç¤º8ç»´åº¦é›·è¾¾å›¾ï¼ˆåœ†å½¢å›¾è¡¨ï¼‰
- [ ] é›·è¾¾å›¾æ˜¾ç¤ºæ‰€æœ‰8ä¸ªç»´åº¦
- [ ] èƒ½å¤ŸæŸ¥çœ‹è¯¦ç»†å¾—åˆ†è¡¨æ ¼
- [ ] èƒ½å¤ŸæŸ¥çœ‹è´¨é‡è¯„ä¼°è¡¨æ ¼

### æ€§èƒ½éªŒæ”¶
- [ ] ç”Ÿæˆ8å¼ å›¾ç‰‡æ—¶é—´ < 10ç§’
- [ ] åˆ†æ8å¼ å›¾ç‰‡æ—¶é—´ < 60ç§’
- [ ] é›·è¾¾å›¾åŠ è½½æ—¶é—´ < 2ç§’

### è´¨é‡éªŒæ”¶
- [ ] ç”Ÿæˆçš„å›¾ç‰‡è´¨é‡è‰¯å¥½
- [ ] é›·è¾¾å›¾ç¾è§‚æ¸…æ™°
- [ ] æ•°æ®å‡†ç¡®å¯é 

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ç”Ÿæˆå›¾ç‰‡å¤±è´¥
**A**: æ£€æŸ¥è¾“å…¥å›¾ç‰‡æ ¼å¼å’Œè·¯å¾„æ˜¯å¦æ­£ç¡®
```powershell
# æ£€æŸ¥å›¾ç‰‡
Get-Item "test_images\test_input.jpg"
```

### Q2: é›·è¾¾å›¾ä¸æ˜¾ç¤º
**A**: æ£€æŸ¥Plotlyæ˜¯å¦æ­£ç¡®å®‰è£…
```powershell
python -c "import plotly; print('Plotlyç‰ˆæœ¬:', plotly.__version__)"
```

### Q3: åˆ†æé€Ÿåº¦æ…¢
**A**: ç¡®ä¿ä½¿ç”¨GPUï¼Œæˆ–å‡å°‘ç”Ÿæˆæ•°é‡
```powershell
python -c "import torch; print('CUDAå¯ç”¨:', torch.cuda.is_available())"
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v4.0 (é‡æ–°è®¾è®¡ç‰ˆ - å¤šè§’åº¦ç”Ÿæˆ+é›·è¾¾å›¾)  
**åˆ›å»ºæ—¥æœŸ**: 2024å¹´11æœˆ  
**æœ€åæ›´æ–°**: 2024å¹´11æœˆ

---

## ğŸ“ é™„å½•ï¼šæ ¸å¿ƒ Python æ–‡ä»¶åˆ›å»ºå‘½ä»¤ï¼ˆPowerShellï¼‰

> **ä½¿ç”¨æ–¹æ³•**ï¼šå¤åˆ¶ä»¥ä¸‹å‘½ä»¤å—åˆ° PowerShell æ‰§è¡Œï¼Œå³å¯åˆ›å»ºå¯¹åº” `.py` æ–‡ä»¶ã€‚ç¡®ä¿å½“å‰ç›®å½•ä¸º `D:\mlflow_learning_project`ã€‚

### A1. åˆ›å»º `agents\image_multi_angle_generator.py`

```powershell
@'
"""
å›¾ç‰‡å¤šè§’åº¦ç”Ÿæˆå™¨
Image Multi-Angle Generator
ä»å•å¼ è¾“å…¥å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦çš„ç´ æå›¾ç‰‡
"""

import numpy as np
import cv2
from PIL import Image
from pathlib import Path
from typing import List, Dict, Optional
import random
from datetime import datetime


class ImageMultiAngleGenerator:
    """å›¾ç‰‡å¤šè§’åº¦ç”Ÿæˆå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.supported_formats = {'.jpg', '.jpeg', '.png', '.bmp'}

    def generate_multi_angle_images(
        self,
        input_image_path: str,
        output_dir: str,
        num_generations: int = 8,
        transformations: List[str] = None
    ) -> Dict:
        """
        ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æ
        """
        input_path = Path(input_image_path)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        if not input_path.exists():
            raise FileNotFoundError(f"è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {input_image_path}")

        img = cv2.imread(str(input_path))
        if img is None:
            pil_img = Image.open(input_path)
            img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

        h, w = img.shape[:2]

        if transformations is None:
            transformations = [
                'original','rotate_15','rotate_-15','rotate_30',
                'flip_horizontal','flip_vertical',
                'brightness_up','brightness_down',
                'contrast_up','contrast_down',
                'saturation_up','saturation_down',
                'blur_slight','sharp',
                'crop_center','crop_corner',
                'zoom_in','zoom_out',
                'perspective','noise'
            ]

        if num_generations > len(transformations):
            selected_transforms = transformations + random.sample(
                transformations,
                num_generations - len(transformations)
            )
        else:
            selected_transforms = random.sample(transformations, num_generations)

        generated_files = []
        metadata = []

        for idx, transform_type in enumerate(selected_transforms, 1):
            try:
                transformed_img = self._apply_transformation(img, transform_type, h, w)
                output_filename = f"generated_{idx:03d}_{transform_type}.jpg"
                output_file = output_path / output_filename
                cv2.imwrite(str(output_file), transformed_img, [cv2.IMWRITE_JPEG_QUALITY, 95])

                generated_files.append(str(output_file))
                metadata.append({
                    'index': idx,
                    'original_path': str(input_path),
                    'generated_path': str(output_file),
                    'transformation': transform_type,
                    'filename': output_filename
                })
            except Exception as e:
                print(f"âš ï¸ ç”Ÿæˆå¤±è´¥ {transform_type}: {e}")
                continue

        metadata_file = output_path / f"generation_metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        import json
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump({
                'generation_time': datetime.now().isoformat(),
                'original_image': str(input_path),
                'output_dir': str(output_path),
                'num_requested': num_generations,
                'num_generated': len(generated_files),
                'generated_images': metadata
            }, f, ensure_ascii=False, indent=2)

        return {
            'success': True,
            'original_image': str(input_path),
            'output_dir': str(output_path),
            'num_generated': len(generated_files),
            'generated_files': generated_files,
            'metadata_file': str(metadata_file)
        }

    def _apply_transformation(self, img: np.ndarray, transform_type: str, h: int, w: int) -> np.ndarray:
        """åº”ç”¨æŒ‡å®šçš„å˜æ¢"""
        result = img.copy()
        if transform_type == 'original':
            return result
        elif transform_type == 'rotate_15':
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, 15, 1.0)
            result = cv2.warpAffine(result, M, (w, h), borderValue=(128, 128, 128))
        elif transform_type == 'rotate_-15':
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, -15, 1.0)
            result = cv2.warpAffine(result, M, (w, h), borderValue=(128, 128, 128))
        elif transform_type == 'rotate_30':
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, 30, 1.0)
            result = cv2.warpAffine(result, M, (w, h), borderValue=(128, 128, 128))
        elif transform_type == 'flip_horizontal':
            result = cv2.flip(result, 1)
        elif transform_type == 'flip_vertical':
            result = cv2.flip(result, 0)
        elif transform_type == 'brightness_up':
            result = cv2.convertScaleAbs(result, alpha=1.2, beta=20)
        elif transform_type == 'brightness_down':
            result = cv2.convertScaleAbs(result, alpha=0.8, beta=-20)
        elif transform_type == 'contrast_up':
            result = cv2.convertScaleAbs(result, alpha=1.3, beta=0)
        elif transform_type == 'contrast_down':
            result = cv2.convertScaleAbs(result, alpha=0.7, beta=0)
        elif transform_type == 'saturation_up':
            hsv = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)
            hsv[:, :, 1] = cv2.multiply(hsv[:, :, 1], 1.3)
            result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        elif transform_type == 'saturation_down':
            hsv = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)
            hsv[:, :, 1] = cv2.multiply(hsv[:, :, 1], 0.7)
            result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        elif transform_type == 'blur_slight':
            result = cv2.GaussianBlur(result, (5, 5), 0)
        elif transform_type == 'sharp':
            kernel = np.array([[-1, -1, -1],[-1, 9, -1],[-1, -1, -1]])
            result = cv2.filter2D(result, -1, kernel)
        elif transform_type == 'crop_center':
            crop_size = min(h, w) * 0.8
            x = int((w - crop_size) / 2)
            y = int((h - crop_size) / 2)
            result = result[y:int(y+crop_size), x:int(x+crop_size)]
            result = cv2.resize(result, (w, h))
        elif transform_type == 'crop_corner':
            crop_size = min(h, w) * 0.8
            result = result[0:int(crop_size), 0:int(crop_size)]
            result = cv2.resize(result, (w, h))
        elif transform_type == 'zoom_in':
            M = cv2.getRotationMatrix2D((w/2, h/2), 0, 1.2)
            result = cv2.warpAffine(result, M, (w, h))
        elif transform_type == 'zoom_out':
            M = cv2.getRotationMatrix2D((w/2, h/2), 0, 0.8)
            result = cv2.warpAffine(result, M, (w, h), borderValue=(128, 128, 128))
        elif transform_type == 'perspective':
            pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])
            pts2 = np.float32([[w*0.1, h*0.1], [w*0.9, h*0.1], [0, h], [w, h]])
            M = cv2.getPerspectiveTransform(pts1, pts2)
            result = cv2.warpPerspective(result, M, (w, h))
        elif transform_type == 'noise':
            noise = np.random.randint(0, 25, result.shape, dtype=np.uint8)
            result = cv2.add(result, noise)

        return result


if __name__ == "__main__":
    generator = ImageMultiAngleGenerator()
    result = generator.generate_multi_angle_images(
        input_image_path="test_image.jpg",
        output_dir="generated",
        num_generations=8
    )
    print(f"ç”Ÿæˆäº† {result['num_generated']} å¼ å›¾ç‰‡")
'@ | Set-Content "agents\image_multi_angle_generator.py" -Encoding UTF8
```

### A2. åˆ›å»º `scripts\generate_from_single_image.py`

```powershell
@'
"""
ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æå¹¶åˆ†æ
Generate Multi-Angle Materials from Single Image and Analyze
"""

import argparse
import json
from pathlib import Path
import sys

project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

from agents.image_multi_angle_generator import ImageMultiAngleGenerator
from agents.image_quality_analyzer import ImageQualityAnalyzer
from agents.material_generator_agent import MaterialGeneratorAgent


def main():
    parser = argparse.ArgumentParser(description="ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æå¹¶åˆ†æ")
    parser.add_argument("--input-image", type=str, required=True, help="è¾“å…¥å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--output-dir", type=str, default="generated_materials", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--num-generations", type=int, default=8, help="ç”Ÿæˆå›¾ç‰‡æ•°é‡")
    parser.add_argument("--analyze", action="store_true", help="ç”Ÿæˆåè‡ªåŠ¨åˆ†æ")
    parser.add_argument("--yolo-model", type=str, default=None, help="YOLOæ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    args = parser.parse_args()

    input_path = Path(args.input_image)
    if not input_path.exists():
        print(f"âŒ è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {args.input_image}")
        return

    print("=" * 60)
    print("ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¤šè§’åº¦ç´ æ")
    print("=" * 60)
    print(f"è¾“å…¥å›¾ç‰‡: {args.input_image}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ç”Ÿæˆæ•°é‡: {args.num_generations}")
    print("=" * 60)

    print("\næ­¥éª¤1: ç”Ÿæˆå¤šè§’åº¦å›¾ç‰‡...")
    generator = ImageMultiAngleGenerator()
    try:
        result = generator.generate_multi_angle_images(
            input_image_path=str(input_path),
            output_dir=args.output_dir,
            num_generations=args.num_generations
        )
        if result['success']:
            print(f"âœ… æˆåŠŸç”Ÿæˆ {result['num_generated']} å¼ å›¾ç‰‡")
            print(f"è¾“å‡ºç›®å½•: {result['output_dir']}")
        else:
            print("âŒ ç”Ÿæˆå¤±è´¥")
            return
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return

    # æ­¥éª¤2: åˆ†æç”Ÿæˆçš„å›¾ç‰‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if args.analyze:
        print("\næ­¥éª¤2: åˆ†æç”Ÿæˆçš„å›¾ç‰‡...")
        analyzer = ImageQualityAnalyzer(yolo_model_path=args.yolo_model)
        agent = MaterialGeneratorAgent(yolo_model_path=args.yolo_model)
        try:
            # åˆ†ææ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡
            analysis_result = agent.analyze_and_evaluate(result['generated_files'])
            
            # ä¿å­˜åˆ†æç»“æœ
            analysis_file = Path(args.output_dir) / f"analysis_result_{Path(result['metadata_file']).stem.split('_')[-1]}.json"
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {analysis_file}")
            print(f"å¹³å‡è´¨é‡: {analysis_result['recommendations']['overall_quality']:.2f}%")
            
        except Exception as e:
            print(f"âš ï¸ åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    print("\nâœ… å¤„ç†å®Œæˆï¼")


if __name__ == "__main__":
    main()
'@ | Set-Content "scripts\generate_from_single_image.py" -Encoding UTF8

# éªŒè¯æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼ˆæ–‡ä»¶åº”è¯¥æœ‰120è¡Œå·¦å³ï¼‰
Write-Host "`néªŒè¯æ–‡ä»¶åˆ›å»º..." -ForegroundColor Cyan
if (Test-Path "scripts\generate_from_single_image.py") {
    $lineCount = (Get-Content "scripts\generate_from_single_image.py" | Measure-Object -Line).Lines
    Write-Host "âœ… æ–‡ä»¶å·²åˆ›å»ºï¼Œå…± $lineCount è¡Œ" -ForegroundColor Green
    if ($lineCount -lt 100) {
        Write-Host "âš ï¸ è­¦å‘Š: æ–‡ä»¶è¡Œæ•°å°‘äºé¢„æœŸï¼Œå¯èƒ½ä¸å®Œæ•´ï¼" -ForegroundColor Yellow
    }
} else {
    Write-Host "âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼" -ForegroundColor Red
}
```

### A3. åˆ›å»º `app\web\material_generator_app.py`

```powershell
@'
"""
æ— äººæœºç´ æå¤šè§’åº¦ç”Ÿæˆä¸åˆ†æç³»ç»Ÿ - Streamlit Webç•Œé¢
"""

import streamlit as st
import plotly.graph_objects as go
import pandas as pd
import numpy as np
from pathlib import Path
import sys
from PIL import Image
import time

project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from agents.image_multi_angle_generator import ImageMultiAngleGenerator
from agents.image_quality_analyzer import ImageQualityAnalyzer
from agents.material_generator_agent import MaterialGeneratorAgent

st.set_page_config(page_title="æ— äººæœºç´ æå¤šè§’åº¦ç”Ÿæˆç³»ç»Ÿ", page_icon="ğŸš", layout="wide")
st.title("ğŸš æ— äººæœºç´ æå¤šè§’åº¦ç”Ÿæˆä¸åˆ†æç³»ç»Ÿ")
st.markdown("**åŠŸèƒ½**: è¾“å…¥ä¸€å¼ å›¾ç‰‡ï¼Œè‡ªåŠ¨ç”Ÿæˆå¤šè§’åº¦ç´ æï¼Œå¹¶ç”Ÿæˆ8ç»´åº¦é›·è¾¾å›¾åˆ†æ")
st.markdown("---")

if 'generator' not in st.session_state:
    st.session_state.generator = ImageMultiAngleGenerator()
if 'agent' not in st.session_state:
    st.session_state.agent = MaterialGeneratorAgent()
if 'generated_images' not in st.session_state:
    st.session_state.generated_images = []
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    num_generations = st.slider("ç”Ÿæˆå›¾ç‰‡æ•°é‡", 4, 20, 8, 1)
    auto_analyze = st.checkbox("ç”Ÿæˆåè‡ªåŠ¨åˆ†æ", value=True)
    st.markdown("---")
    st.markdown("### ğŸ“Š 8ä¸ªåˆ†æç»´åº¦")
    for dim in [
        "1. å›¾ç‰‡æ•°æ®é‡","2. æ‹æ‘„å…‰ç…§è´¨é‡","3. ç›®æ ‡å°ºå¯¸","4. ç›®æ ‡å®Œæ•´æ€§",
        "5. æ•°æ®å‡è¡¡åº¦","6. äº§å“ä¸°å¯Œåº¦","7. ç›®æ ‡å¯†é›†åº¦","8. åœºæ™¯å¤æ‚åº¦"
    ]:
        st.markdown(f"- {dim}")

st.header("ğŸ“¸ ä¸Šä¼ å›¾ç‰‡å¹¶ç”Ÿæˆå¤šè§’åº¦ç´ æ")
uploaded_file = st.file_uploader("ä¸Šä¼ ä¸€å¼ æ— äººæœºå›¾ç‰‡", type=['jpg','jpeg','png','bmp'])

if uploaded_file is not None:
    temp_dir = Path("temp_uploads")
    temp_dir.mkdir(exist_ok=True)
    temp_path = temp_dir / uploaded_file.name
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    col1, col2 = st.columns([1,1])
    with col1:
        st.subheader("ğŸ“· åŸå§‹å›¾ç‰‡")
        st.image(uploaded_file, caption="ä¸Šä¼ çš„åŸå§‹å›¾ç‰‡", use_container_width=True)

    with col2:
        st.subheader("ğŸ¯ æ“ä½œ")
        if st.button("ğŸš€ ç”Ÿæˆå¤šè§’åº¦ç´ æå¹¶åˆ†æ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨ç”Ÿæˆå¤šè§’åº¦ç´ æï¼Œè¯·ç¨å€™..."):
                try:
                    output_dir = Path("generated_materials") / f"generation_{int(time.time())}"
                    output_dir.mkdir(parents=True, exist_ok=True)
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    status_text.text("æ­¥éª¤1/2: æ­£åœ¨ç”Ÿæˆå¤šè§’åº¦ç´ æ...")
                    result = st.session_state.generator.generate_multi_angle_images(
                        input_image_path=str(temp_path),
                        output_dir=str(output_dir),
                        num_generations=num_generations
                    )
                    progress_bar.progress(50)
                    status_text.text(f"âœ… å·²ç”Ÿæˆ {result['num_generated']} å¼ ç´ æ")
                    st.session_state.generated_images = result['generated_files']

                    if auto_analyze:
                        status_text.text("æ­¥éª¤2/2: æ­£åœ¨åˆ†æç”Ÿæˆçš„ç´ æ...")
                        analysis_result = st.session_state.agent.analyze_and_evaluate(
                            result['generated_files']
                        )
                        st.session_state.analysis_results = analysis_result
                        progress_bar.progress(100)
                        status_text.text("âœ… åˆ†æå®Œæˆï¼")
                    else:
                        progress_bar.progress(100)
                        status_text.text("âœ… ç”Ÿæˆå®Œæˆï¼")

                    st.success(f"âœ… æˆåŠŸç”Ÿæˆ {result['num_generated']} å¼ å¤šè§’åº¦ç´ æï¼")
                except Exception as e:
                    st.error(f"âŒ å¤„ç†å‡ºé”™: {e}")

    if st.session_state.generated_images:
        st.markdown("---")
        st.subheader("ğŸ¨ ç”Ÿæˆçš„å¤šè§’åº¦ç´ æ")
        num_cols = 4
        images = st.session_state.generated_images
        for i in range(0, len(images), num_cols):
            cols = st.columns(num_cols)
            for j, col in enumerate(cols):
                if i + j < len(images):
                    img_path = Path(images[i + j])
                    if img_path.exists():
                        col.image(Image.open(img_path), caption=img_path.name, use_container_width=True)

    if st.session_state.analysis_results:
        st.markdown("---")
        st.subheader("ğŸ“Š 8ç»´åº¦é›·è¾¾å›¾åˆ†æ")
        avg_scores = st.session_state.analysis_results['analysis']['average_scores']
        fig = go.Figure()
        dimensions = [
            "å›¾ç‰‡æ•°æ®é‡","æ‹æ‘„å…‰ç…§è´¨é‡","ç›®æ ‡å°ºå¯¸","ç›®æ ‡å®Œæ•´æ€§",
            "æ•°æ®å‡è¡¡åº¦","äº§å“ä¸°å¯Œåº¦","ç›®æ ‡å¯†é›†åº¦","åœºæ™¯å¤æ‚åº¦"
        ]
        values = [avg_scores.get(dim,0) for dim in dimensions]
        fig.add_trace(go.Scatterpolar(
            r=values + [values[0]],
            theta=dimensions + [dimensions[0]],
            fill='toself',
            name='ç»´åº¦å¾—åˆ†',
            line=dict(color='rgb(31,119,180)', width=3),
            fillcolor='rgba(31,119,180,0.25)'
        ))
        avg_score = np.mean(values)
        fig.add_trace(go.Scatterpolar(
            r=[avg_score]*(len(dimensions)+1),
            theta=dimensions + [dimensions[0]],
            name=f'å¹³å‡çº¿ ({avg_score:.1f}%)',
            line=dict(color='rgb(255,127,14)', width=2, dash='dash')
        ))
        fig.update_layout(
            polar=dict(
                radialaxis=dict(visible=True, range=[0,100]),
                angularaxis=dict(rotation=90, direction='counterclockwise')
            ),
            showlegend=True,
            title="8ç»´åº¦è´¨é‡åˆ†æé›·è¾¾å›¾",
            height=600
        )
        st.plotly_chart(fig, use_container_width=True)

        col1, col2 = st.columns([2,1])
        with col1:
            st.markdown("#### ğŸ“ˆ ç»´åº¦å¾—åˆ†è¯¦æƒ…")
            score_df = pd.DataFrame([
                {"ç»´åº¦": dim, "å¾—åˆ†": f"{score:.2f}%", "ç­‰çº§": "ä¼˜ç§€ â­â­â­" if score>=90 else "è‰¯å¥½ â­â­" if score>=80 else "ä¸­ç­‰ â­" if score>=70 else "ä¸€èˆ¬" if score>=60 else "è¾ƒå·®"}
                for dim, score in avg_scores.items()
            ])
            st.dataframe(score_df, use_container_width=True, hide_index=True)
        with col2:
            st.markdown("#### ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
            overall_quality = st.session_state.analysis_results['recommendations']['overall_quality']
            st.metric("æ•´ä½“è´¨é‡", f"{overall_quality:.2f}%")
            st.metric("ç”Ÿæˆç´ ææ•°", len(st.session_state.generated_images))
            st.metric("åˆ†æç´ ææ•°", st.session_state.analysis_results['analysis']['total_images'])

        st.markdown("#### ğŸ“‹ ç´ æè´¨é‡è¯„ä¼°")
        quality_data = []
        for item in st.session_state.analysis_results['quality_evaluation']:
            quality_data.append({
                "ç´ æ": Path(item['image_path']).name,
                "å¹³å‡å¾—åˆ†": f"{item['average_score']:.2f}%",
                "è´¨é‡ç­‰çº§": item['quality_level']
            })
        st.dataframe(pd.DataFrame(quality_data), use_container_width=True, hide_index=True)


if __name__ == "__main__":
    st.run()
'@ | Set-Content "app\web\material_generator_app.py" -Encoding UTF8
```

